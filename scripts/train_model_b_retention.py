import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, mean_squared_error
from sklearn.calibration import calibration_curve
import json
import sys
from catboost import CatBoostClassifier, Pool
from datetime import datetime

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")

# optimal_preprocess_full ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
from optimal_preprocess_full import BTestPreprocessor
from pre_b import (
    build_primarykey_testdate_dict,
    add_primarykey_month_diff_features,
)
from generate_retention_features_fast import (
    build_gap_label_same_statistics,
    build_consecutive_00_statistics,
    add_retention_features_fast,
)


def _normalize_test_date(value):
    """Convert TestDate value to integer timestamp (seconds)"""
    if value is None or (isinstance(value, float) and np.isnan(value)):
        return None

    ts = None

    # ì´ë¯¸ Timestamp/Datetime ê°ì²´ì¸ ê²½ìš°
    if isinstance(value, (pd.Timestamp, datetime)):
        ts = value
    else:
        # ìˆ«ìí˜•ì¸ ê²½ìš° ìœ í˜•ë³„ë¡œ ì²˜ë¦¬
        if isinstance(value, (np.integer, int, np.floating, float)):
            # ì •ìˆ˜/ì‹¤ìˆ˜ â†’ ìš°ì„  ì •ìˆ˜ë¡œ ë³€í™˜
            try:
                numeric_val = int(value)
            except (TypeError, ValueError, OverflowError):
                numeric_val = None

            if numeric_val is None:
                return None

            # 1970ë…„ ì´í›„ ì´ˆ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì • (ì•½ 2001ë…„ ì´í›„ ê°’)
            if numeric_val >= 10**9:
                ts = pd.to_datetime(numeric_val, unit='s', errors='coerce')
            else:
                value_str = str(numeric_val)
                # ê¸¸ì´ì— ë”°ë¼ YYYYMM / YYYYMMDD / YYYYMMDDHHMM ë“± ì¶”ì •
                parse_formats = ['%Y%m', '%Y%m%d', '%Y%m%d%H%M', '%Y%m%d%H%M%S']
                for fmt in parse_formats:
                    ts = pd.to_datetime(value_str, format=fmt, errors='coerce')
                    if not pd.isna(ts):
                        break
        else:
            # ë¬¸ìì—´ ë“±ì€ to_datetimeìœ¼ë¡œ ì§ì ‘ íŒŒì‹±
            ts = pd.to_datetime(value, errors='coerce')

    if ts is None or pd.isna(ts):
        return None

    return int(ts.value // 10**9)


def build_label_pattern_history(df, save_path: str | None = None):
    """
    ì „ì²´ train ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ì—¬ PrimaryKeyë³„ë¡œ TestDate ìˆœì„œëŒ€ë¡œ Label ì‹œí€€ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
    """
    required_cols = {'PrimaryKey', 'TestDate', 'Label'}
    if not required_cols.issubset(df.columns):
        return {}

    hist = {}

    df_work = df[list(required_cols)].copy()
    df_work = df_work.dropna(subset=['PrimaryKey', 'Label'])

    for pk, group in df_work.groupby('PrimaryKey'):
        pk_list = []
        for _, row in group.iterrows():
            test_date = _normalize_test_date(row['TestDate'])
            if test_date is None:
                continue

            try:
                label_val = int(row['Label'])
            except (TypeError, ValueError):
                continue

            pk_list.append((test_date, label_val))

        if len(pk_list) == 0:
            continue

        pk_list.sort(key=lambda x: x[0])
        hist[str(pk)] = pk_list

    if save_path:
        save_dir = os.path.dirname(save_path)
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(hist, f, ensure_ascii=False, indent=2)

    return hist


def add_label_pattern_features(df: pd.DataFrame, label_pattern_history: dict,
                               out_col_prefix: str = 'pattern') -> pd.DataFrame:
    """
    ê° í–‰ì— ëŒ€í•´ TestDate ì´ì „ ì‹œì ê¹Œì§€ì˜ 4ê°€ì§€ íŒ¨í„´ ì¶œí˜„ íšŸìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ íŒŒìƒë³€ìˆ˜ ìƒì„±
    """
    df_copy = df.copy()

    pattern_cols = [
        f'{out_col_prefix}_1to1',
        f'{out_col_prefix}_1to0',
        f'{out_col_prefix}_0to1',
        f'{out_col_prefix}_0to0',
    ]

    if 'PrimaryKey' not in df_copy.columns or 'TestDate' not in df_copy.columns:
        for col in pattern_cols:
            df_copy[col] = 0
        return df_copy

    def count_patterns(row):
        pk_val = row.get('PrimaryKey')
        if pd.isna(pk_val):
            return 0, 0, 0, 0

        pk = str(pk_val)
        current_date = _normalize_test_date(row.get('TestDate'))
        if current_date is None or pk not in label_pattern_history:
            return 0, 0, 0, 0

        pk_list = label_pattern_history[pk]
        prev_list = [(td, label) for td, label in pk_list if td < current_date]

        if len(prev_list) < 2:
            return 0, 0, 0, 0

        pattern_1to1 = pattern_1to0 = pattern_0to1 = pattern_0to0 = 0

        for i in range(1, len(prev_list)):
            prev_label = prev_list[i - 1][1]
            curr_label = prev_list[i][1]

            if prev_label == 1 and curr_label == 1:
                pattern_1to1 += 1
            elif prev_label == 1 and curr_label == 0:
                pattern_1to0 += 1
            elif prev_label == 0 and curr_label == 1:
                pattern_0to1 += 1
            elif prev_label == 0 and curr_label == 0:
                pattern_0to0 += 1

        return pattern_1to1, pattern_1to0, pattern_0to1, pattern_0to0

    patterns = df_copy.apply(count_patterns, axis=1, result_type='expand')
    for idx, col in enumerate(pattern_cols):
        df_copy[col] = patterns[idx].fillna(0).astype(int)

    return df_copy


def add_label_count_features(df: pd.DataFrame, 
                             label_pattern_history_b: dict,
                             label_pattern_history_a: dict = None) -> pd.DataFrame:
    """í˜„ì¬ TestDate ì´ì „ê¹Œì§€ Bì™€ A ê°ê°ì˜ ì´ ê¸°ë¡ ìˆ˜, A ìµœì‹  ê¸°ë¡ê³¼ì˜ ì›” ì°¨ì´, A ìµœì‹  ë¼ë²¨ê³¼ B ìµœì´ˆ ë¼ë²¨ ì¼ì¹˜ ì—¬ë¶€ë¥¼ ê³„ì‚°"""
    df_copy = df.copy()

    b_total_col = 'b_past_label_total_count'
    a_total_col = 'a_past_label_total_count'
    a_last_month_diff_col = 'a_last_testdate_month_diff'
    label_match_col = 'a_last_b_first_label_match'

    df_copy[b_total_col] = 0
    df_copy[a_total_col] = 0
    df_copy[a_last_month_diff_col] = -1
    df_copy[label_match_col] = -1

    if 'PrimaryKey' not in df_copy.columns or 'TestDate' not in df_copy.columns:
        return df_copy

    def count_prev_records(row):
        pk = str(row.get('PrimaryKey', ''))
        if not pk:
            return 0, 0, -1, -1

        current_ts = _normalize_test_date(row.get('TestDate'))
        if current_ts is None:
            return 0, 0, -1, -1

        # B ê¸°ë¡ ìˆ˜ ê³„ì‚°
        b_count = 0
        b_first_label = None
        if pk in label_pattern_history_b:
            pk_list_b = label_pattern_history_b[pk]
            prev_b = [(ts, label) for ts, label in pk_list_b if ts < current_ts]
            b_count = len(prev_b)
            if prev_b:
                b_first_label = prev_b[0][1]  # ê°€ì¥ ì˜¤ë˜ëœ B ë¼ë²¨

        # A ê¸°ë¡ ìˆ˜ ê³„ì‚° ë° A ìµœì‹  TestDateì™€ì˜ ì›” ì°¨ì´ ê³„ì‚°
        a_count = 0
        a_month_diff = -1
        a_last_label = None
        if label_pattern_history_a and pk in label_pattern_history_a:
            pk_list_a = label_pattern_history_a[pk]
            prev_a = [(ts, label) for ts, label in pk_list_a if ts < current_ts]
            a_count = len(prev_a)
            
            if prev_a:
                # ê°€ì¥ ìµœê·¼ A ê¸°ë¡ì˜ TestDateì™€ Label
                last_a_ts = prev_a[-1][0]
                a_last_label = prev_a[-1][1]
                try:
                    # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë‚ ì§œë¡œ ë³€í™˜
                    from datetime import datetime
                    current_dt = datetime.fromtimestamp(current_ts)
                    last_a_dt = datetime.fromtimestamp(last_a_ts)
                    # ì›” ì°¨ì´ ê³„ì‚°
                    a_month_diff = (current_dt.year - last_a_dt.year) * 12 + (current_dt.month - last_a_dt.month)
                except:
                    a_month_diff = -1

        # A ìµœì‹  ë¼ë²¨ê³¼ B ìµœì´ˆ ë¼ë²¨ ì¼ì¹˜ ì—¬ë¶€ (ë‘˜ ë‹¤ ìˆì„ ë•Œë§Œ)
        label_match = -1
        if a_last_label is not None and b_first_label is not None:
            label_match = 1 if a_last_label == b_first_label else 0

        return b_count, a_count, a_month_diff, label_match

    counts = df_copy.apply(count_prev_records, axis=1, result_type='expand')
    df_copy[b_total_col] = counts[0].fillna(0).astype(int)
    df_copy[a_total_col] = counts[1].fillna(0).astype(int)
    df_copy[a_last_month_diff_col] = counts[2].fillna(-1).astype(int)
    df_copy[label_match_col] = counts[3].fillna(-1).astype(int)
    return df_copy


def expected_calibration_error(y_true, y_prob, n_bins=10):
    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=n_bins, strategy="uniform")
    bin_totals = np.histogram(y_prob, bins=np.linspace(0, 1, n_bins + 1), density=False)[0]
    non_empty_bins = bin_totals > 0
    bin_weights = bin_totals / len(y_prob)
    bin_weights = bin_weights[non_empty_bins]
    prob_true = prob_true[:len(bin_weights)]
    prob_pred = prob_pred[:len(bin_weights)]
    ece = np.sum(bin_weights * np.abs(prob_true - prob_pred))
    return ece

def competition_metric(y_true, y_prob):
    auc = roc_auc_score(y_true, y_prob)
    brier = mean_squared_error(y_true, y_prob)
    ece = expected_calibration_error(y_true, y_prob)
    score = 0.5 * (1 - auc) + 0.25 * brier + 0.25 * ece
    return score, auc, brier, ece

if __name__ == "__main__":
    data_dir = DATA_DIR
    train_label = pd.read_csv(data_dir+"/train.csv")
    print(f"âœ… train_label loaded: {train_label.shape}")

    # =========================================================
    # ğŸ”¸ A ë°ì´í„° ë¡œë“œ ë° ë”•ì…”ë„ˆë¦¬ ìƒì„±
    # =========================================================
    print("\nğŸ“š A ë°ì´í„° ë¡œë“œ ë° dict_A ìƒì„±...")
    A_feat = pd.read_csv(data_dir+"/train/A.csv")
    dfA = train_label[train_label["Test"] == "A"].merge(A_feat, on=["Test_id", "Test"], how="left")
    print(f"âœ… A merged shape: {dfA.shape}")
    
    dict_A = dfA.groupby('PrimaryKey')['Label'].max().to_dict()
    print(f"âœ… dict_A ìƒì„± ì™„ë£Œ: {len(dict_A)} keys")
    
    # =========================================================
    # ğŸ”¸ B ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (optimal_preprocess_full ì‚¬ìš©)
    # =========================================================
    print("\nğŸ“Š B ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘ (optimal_preprocess_full)...")
    print("âš¡ ìµœì í™”ëœ ê³¼ê±° ì´ë ¥ ê³„ì‚° (ë²¡í„°í™”) ì ìš©!")
    B_feat = pd.read_csv(data_dir+"/train/B.csv")
    dfB = train_label[train_label["Test"] == "B"].merge(B_feat, on=["Test_id", "Test"], how="left")
    print(f"âœ… B merged shape: {dfB.shape}")

    # Label pattern history ìƒì„± ë° ì €ì¥ (Bì™€ A ê°ê°)
    print("\nğŸ§  B Label pattern history ìƒì„± ì¤‘...")
    label_pattern_history_b_path = "models/label_pattern_history_b.json"
    label_pattern_history_b = build_label_pattern_history(
        dfB[["PrimaryKey", "TestDate", "Label"]].copy(),
        save_path=label_pattern_history_b_path
    )
    print(f"âœ… B Label pattern history ìƒì„± ì™„ë£Œ: {len(label_pattern_history_b)} keys â†’ {label_pattern_history_b_path}")

    print("ğŸ§  A Label pattern history ìƒì„± ì¤‘...")
    label_pattern_history_a_path = "models/label_pattern_history_a.json"
    label_pattern_history_a = build_label_pattern_history(
        dfA[["PrimaryKey", "TestDate", "Label"]].copy(),
        save_path=label_pattern_history_a_path
    )
    print(f"âœ… A Label pattern history ìƒì„± ì™„ë£Œ: {len(label_pattern_history_a)} keys â†’ {label_pattern_history_a_path}")

    # PrimaryKey-TestDate dictionary & month diff features
    print("\nğŸ—“ PrimaryKey-TestDate dict ìƒì„± ì¤‘...")
    pk_testdate_dict_path = "models/primarykey_testdate_dict_b.json"
    pk_testdate_dict = build_primarykey_testdate_dict(
        dfB[["PrimaryKey", "TestDate"]].copy(),
        save_path=pk_testdate_dict_path
    )
    print(f"âœ… PrimaryKey-TestDate dict ìƒì„± ì™„ë£Œ: {len(pk_testdate_dict)} keys â†’ {pk_testdate_dict_path}")

    print("â• ì›”ê°„ ê°„ê²© íŒŒìƒë³€ìˆ˜ ì¶”ê°€ ì¤‘...")
    dfB = add_primarykey_month_diff_features(dfB, pk_testdate_dict)

    print("â• ê³¼ê±° B/A ê¸°ë¡ ìˆ˜ ê³„ì‚° ì¤‘...")
    dfB = add_label_count_features(dfB, label_pattern_history_b, label_pattern_history_a)
    
    # Gapë³„ Label Same Rate í†µê³„ ê³„ì‚° (Aâ†’B í˜ì–´ë§Œ)
    print("\nğŸ§® Gapë³„ Label Same Rate í†µê³„ ê³„ì‚° ì¤‘...")
    gap_stats_month, gap_stats_bin = build_gap_label_same_statistics(
        dfA[["PrimaryKey", "TestDate", "Label"]].copy(),
        dfB[["PrimaryKey", "TestDate", "Label"]].copy(),
        save_dir="models"
    )
    print(f"âœ… Gap í†µê³„ ê³„ì‚° ì™„ë£Œ!")
    
    # Consecutive 0-0 ìœ ì§€ìœ¨ í†µê³„ ê³„ì‚°
    print("\nğŸ§® Consecutive 0-0 ìœ ì§€ìœ¨ í†µê³„ ê³„ì‚° ì¤‘...")
    consecutive_00_stats_month, consecutive_00_stats_bin = build_consecutive_00_statistics(
        dfB[["PrimaryKey", "TestDate", "Label"]].copy(),
        save_dir="models"
    )
    print(f"âœ… Consecutive 0-0 í†µê³„ ê³„ì‚° ì™„ë£Œ!")
    
    # ìœ ì§€ìœ¨ íŒŒìƒë³€ìˆ˜ ì¶”ê°€ (LabelSameRate_gap + Consecutive00_RetentionRate)
    print("\nâ• ìœ ì§€ìœ¨ íŒŒìƒë³€ìˆ˜ ì¶”ê°€ ì¤‘...")
    dfB = add_retention_features_fast(
        dfB,
        dfA[["PrimaryKey", "TestDate", "Label"]].copy(),
        gap_stats_bin,
        gap_stats_month,
        consecutive_00_stats_bin,
        consecutive_00_stats_month
    )
    print(f"âœ… ìœ ì§€ìœ¨ íŒŒìƒë³€ìˆ˜ ì¶”ê°€ ì™„ë£Œ!")
    
    # BTestPreprocessor ì´ˆê¸°í™” ë° í•™ìŠµ
    print("\nğŸ”§ BTestPreprocessor fit...")
    preprocessor = BTestPreprocessor(dict_A=dict_A)
    preprocessor.fit(dfB)
    print(f"âœ… Preprocessor fitted!")
    
    # ì „ì²´ B ë°ì´í„° ì „ì²˜ë¦¬ (56 columns: 51 PCs + 5 metadata)
    print("\nğŸ”„ B ë°ì´í„° ì „ì²˜ë¦¬ (transform)...")
    dfB_processed = preprocessor.transform(dfB)
    dfB_processed = add_label_pattern_features(dfB_processed, label_pattern_history_b, out_col_prefix='pattern')
    dfB_processed['PK_prev_month_diff'] = dfB['PK_prev_month_diff'].values
    dfB_processed['PK_avg_prev_month_diff'] = dfB['PK_avg_prev_month_diff'].values
    # dfB_processed['b_past_label_total_count'] = dfB['b_past_label_total_count'].values
    # dfB_processed['a_past_label_total_count'] = dfB['a_past_label_total_count'].values
    # dfB_processed['a_last_testdate_month_diff'] = dfB['a_last_testdate_month_diff'].values
    # dfB_processed['a_last_b_first_label_match'] = dfB['a_last_b_first_label_match'].values
    dfB_processed['LabelSameRate_gap'] = dfB['LabelSameRate_gap'].values
    dfB_processed['Consecutive00_RetentionRate'] = dfB['Consecutive00_RetentionRate'].values
    print(f"âœ… B ì „ì²˜ë¦¬ ì™„ë£Œ! Shape: {dfB_processed.shape}")
    print(f"   Columns: {list(dfB_processed.columns)[:10]}...")
    
    # Labelê³¼ Test_id ì¶”ê°€
    dfB_processed['Label'] = dfB['Label'].values
    dfB_processed['Test_id'] = dfB['Test_id'].values
    
    # =========================================================
    # ğŸ”¸ Train/Val Split
    # =========================================================
    print("\nâœ‚ï¸ Train/Val Split...")
    X_tr, X_val, y_tr, y_val = train_test_split(
        dfB_processed,
        dfB_processed["Label"],
        test_size=0.15,
        stratify=dfB_processed["Label"],
        random_state=42
    )
    print(f"Train shape: {X_tr.shape}, Val shape: {X_val.shape}")

    # ================================Train ì¤€ë¹„=============================================
    print("\nğŸ“‹ Train ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    train_Y = X_tr["Label"].values
    train_X = X_tr.drop(columns=["Label", "Test_id"], errors="ignore")

    categorical_columns = ['past_A_history']

    for col in categorical_columns:
        if col in train_X.columns:
            train_X[col] = train_X[col].astype(str)

    if 'TestDate' in train_X.columns:
        train_X['TestDate'] = pd.to_datetime(train_X['TestDate']).astype(np.int64) // 10**9

    drop_feature_cols = ['PrimaryKey', 'past_label_prev_label', 'past_label_label1_flag', 'past_label_label1_count', 
                          'b_past_label_total_count', 'a_past_label_total_count', 'a_last_testdate_month_diff',
                          'a_last_b_first_label_match']
    train_X = train_X.drop(columns=drop_feature_cols, errors='ignore')

    numeric_cols = train_X.select_dtypes(include=[np.number]).columns
    train_X[numeric_cols] = train_X[numeric_cols].fillna(-999)

    meta_data = train_X.columns.tolist()
    print(f"âœ… Train features: {len(meta_data)} columns")
    print(f"   Categorical: {categorical_columns}")

    cat_feature_indices = [
        i for i, col in enumerate(train_X.columns)
        if col in categorical_columns
    ]

    # ==========================================================================================
    # ğŸ”¸ Validation ì¤€ë¹„
    # ==========================================================================================
    print("\nğŸ“‹ Validation ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    val_Y = y_val.values
    val_X = X_val.drop(columns=["Label", "Test_id"], errors="ignore")

    for col in categorical_columns:
        if col in val_X.columns:
            val_X[col] = val_X[col].astype(str)

    if 'TestDate' in val_X.columns:
        val_X['TestDate'] = pd.to_datetime(val_X['TestDate']).astype(np.int64) // 10**9

    val_X = val_X.drop(columns=drop_feature_cols, errors='ignore')

    numeric_cols = val_X.select_dtypes(include=[np.number]).columns
    val_X[numeric_cols] = val_X[numeric_cols].fillna(-999)

    print(f"âœ… Validation features: {val_X.shape[1]} columns")
    print(f"ğŸ“Š ìµœì¢… shape: Train X={train_X.shape}, y={train_Y.shape} | Val X={val_X.shape}, y={val_Y.shape}")
    
    # =========================================================
    # ğŸ”¸ CatBoost ëª¨ë¸ í•™ìŠµ
    # =========================================================
    print("\nğŸš€ CatBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    b_param = {
        "iterations": 3000,
        "learning_rate": 0.005,
        "depth": 9,
        "l2_leaf_reg": 10,
        "bootstrap_type": "Bernoulli",
        "eval_metric": "AUC",
        "subsample": 1,
        "task_type": "CPU",
        "verbose": 100,
    }

    # CatBoost Pool ìƒì„±
    train_pool = Pool(train_X, train_Y, cat_features=cat_feature_indices)
    val_pool = Pool(val_X, val_Y, cat_features=cat_feature_indices)

    # Model training with validation
    model = CatBoostClassifier(**b_param)
    model.fit(
        train_pool,
        eval_set=val_pool,
        early_stopping_rounds=200,
        use_best_model=True,
    )

    # Validation performance
    prob_val = model.predict_proba(val_X)[:, 1]
    score, auc, brier, ece = competition_metric(val_Y, prob_val)
    print(f"\n{'='*60}")
    print(f"ğŸ¯ Validation ì„±ëŠ¥")
    print(f"{'='*60}")
    print(f"AUC   = {auc:.4f}")
    print(f"Brier = {brier:.4f}")
    print(f"ECE   = {ece:.4f}")
    print(f"Score = {score:.6f}")
    print(f"{'='*60}\n")
    
    out_path = "models"
    # Save model
    out_path = out_path + f"/cat_{score:.6f}.cbm"
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    model.save_model(out_path)
    print(f"âœ… CatBoost model saved â†’ {out_path}")
    
    # =========================================================
    # ğŸ”¸ dict_A ì €ì¥ (ì¶”ë¡  ì‹œ ì‚¬ìš©)
    # =========================================================
    dict_A_path = "models/dict_A.json"
    with open(dict_A_path, 'w', encoding='utf-8') as f:
        json.dump({str(k): int(v) for k, v in dict_A.items()}, f, ensure_ascii=False, indent=2)
    print(f"âœ… dict_A saved â†’ {dict_A_path}")
    
    # =========================================================
    # ğŸ”¸ Preprocessor ì €ì¥ (Test ì¶”ë¡  ì‹œ í•„ìˆ˜!)
    # =========================================================
    import pickle
    preprocessor_path = "models/preprocessor.pkl"
    with open(preprocessor_path, 'wb') as f:
        pickle.dump(preprocessor, f)
    print(f"âœ… Preprocessor (ëª¨ë“  PCA í¬í•¨) saved â†’ {preprocessor_path}")
    print(f"   - ì´ íŒŒì¼ì€ Test ë°ì´í„° ì „ì²˜ë¦¬ ì‹œ í•„ìˆ˜ì…ë‹ˆë‹¤!")

    # =========================================================
    # ğŸ”¸ Feature ì´ë¦„ ì €ì¥
    # =========================================================
    feature_names_path = "models/feature_names.json"
    feature_payload = {
        "features": meta_data,
        "categorical_features": [col for col in categorical_columns if col in meta_data],
        "cat_feature_indices": cat_feature_indices,
    }
    with open(feature_names_path, 'w', encoding='utf-8') as f:
        json.dump(feature_payload, f, ensure_ascii=False, indent=2)
    print(f"âœ… Feature ì´ë¦„ saved â†’ {feature_names_path}")
    
    # =========================================================
    # ğŸ”¸ ìµœì¢… B DataFrame ì €ì¥ (LabelSameRate_gap í¬í•¨)
    # =========================================================
    b_with_label_same_rate_path = "models/b_with_label_same_rate.csv"
    dfB.to_csv(b_with_label_same_rate_path, index=False, encoding='utf-8')
    print(f"âœ… B with LabelSameRate_gap saved â†’ {b_with_label_same_rate_path}")
    
    # =========================================================
    # ğŸ“‹ í•„ìš” íŒŒì¼ ëª©ë¡ ì¶œë ¥
    # =========================================================
    print(f"\n{'='*60}")
    print(f"ğŸ“¦ Test ì¶”ë¡  ì‹œ í•„ìš”í•œ íŒŒì¼ë“¤:")
    print(f"{'='*60}")
    print(f"1. {preprocessor_path} (ì „ì²˜ë¦¬ ê°ì²´ - ëª¨ë“  PCA í¬í•¨)")
    print(f"2. {dict_A_path} (A ê³¼ê±° ì´ë ¥)")
    print(f"3. {out_path} (í•™ìŠµëœ CatBoost ëª¨ë¸)")
    print(f"4. optimal_preprocess_full.py (ì „ì²˜ë¦¬ ì½”ë“œ)")
    print(f"5. models/gap_label_same_rate_stats.json (LabelSameRate í†µê³„)")
    print(f"6. models/gap_label_same_rate_month.csv (ì›”ë³„ í†µê³„)")
    print(f"7. models/gap_label_same_rate_bin.csv (Binë³„ í†µê³„)")
    print(f"8. models/consecutive_00_retention_stats.json (Consecutive00 í†µê³„)")
    print(f"9. models/consecutive_00_retention_month.csv (ì›”ë³„ 00 í†µê³„)")
    print(f"10. models/consecutive_00_retention_bin.csv (Binë³„ 00 í†µê³„)")
    print(f"11. {b_with_label_same_rate_path} (B ë°ì´í„° with ìœ ì§€ìœ¨ ë³€ìˆ˜)")
    print(f"{'='*60}")
