# pre_b utilities
import os, json
import numpy as np
import pandas as pd
from scipy import stats

def preprocess_b_features(df):
    
    # ------------------ ìœ í‹¸ í•¨ìˆ˜ë“¤ ------------------
    def convert_age_features(df, col="Age"):
        def _convert(val):
            if pd.isna(val):
                return np.nan
            s = str(val).strip()
            if not s:
                return np.nan
            try:
                base = int(s[:-1])
                return base if s[-1] == "a" else base + 5
            except:
                try:
                    return int(s)
                except:
                    return np.nan
        df = df.copy()
        if col in df.columns:
            df[f"{col}_num"] = df[col].apply(_convert)
        return df

    def count_minus_values(series):
        def _count_minus(val):
            if pd.isna(val) or val == "":
                return 0
            try:
                values = [float(x.strip()) for x in str(val).split(",") if x.strip()]
                return sum(1 for v in values if v < 0)
            except:
                return 0
        return series.fillna("").apply(_count_minus)

    def count_ones(series):
        def _count_ones(val):
            if pd.isna(val) or val == "":
                return 0
            try:
                values = [int(float(x.strip())) for x in str(val).split(",") if x.strip()]
                return sum(1 for v in values if v == 1)
            except:
                return 0
        return series.fillna("").apply(_count_ones)

    def count_zeros(series):
        def _count_zeros(val):
            if pd.isna(val) or val == "":
                return 0
            try:
                values = [float(x.strip()) for x in str(val).split(",") if x.strip()]
                return sum(1 for v in values if v == 0.0)
            except:
                return 0
        return series.fillna("").apply(_count_zeros)

    def count_up_one_or_zero(series):
        def _count_condition(val):
            if pd.isna(val) or val == "":
                return 0
            try:
                values = [float(x.strip()) for x in str(val).split(",") if x.strip()]
                return sum(1 for v in values if (v >= 1.0) or (v == 0.0))
            except:
                return 0
        return series.fillna("").apply(_count_condition)

    def parse_list_column(col):
        """ë¬¸ìì—´ -> ë¦¬ìŠ¤íŠ¸(ìˆ«ìë¡œ ë³€í™˜ ì‹œë„). NaN -> []"""
        if pd.isna(col):
            return []
        s = str(col).strip()
        if s == "":
            return []
        parts = s.split(',')
        out = []
        for p in parts:
            p = p.strip()
            if p == "":
                continue
            try:
                if '.' in p:
                    out.append(float(p))
                else:
                    out.append(int(p))
            except:
                try:
                    out.append(float(p))
                except:
                    out.append(p)
        return out

    def safe_mean(lst):
        if not lst:
            return np.nan
        try:
            nums = [x for x in lst if isinstance(x, (int, float, np.number))]
            if not nums:
                return np.nan
            return float(np.mean(nums))
        except:
            return np.nan

    def safe_std(lst):
        if not lst or len(lst) < 2:
            return np.nan
        try:
            nums = [x for x in lst if isinstance(x, (int, float, np.number))]
            if len(nums) < 2:
                return np.nan
            return float(np.std(nums))
        except:
            return np.nan

    def mean_rt_by_codes(resp_list, rt_list, code_set):
        if not isinstance(resp_list, (list, tuple)) or not isinstance(rt_list, (list, tuple)):
            return np.nan
        L = min(len(resp_list), len(rt_list))
        selected = [rt_list[i] for i in range(L) if resp_list[i] in code_set and isinstance(rt_list[i], (int, float, np.number))]
        return safe_mean(selected)

    def rt_diff_correct_incorrect(rt_list, resp_list):
        """ì •ë‹µê³¼ ì˜¤ë‹µì˜ ë°˜ì‘ì‹œê°„ ì°¨ì´"""
        correct_rt = [rt for rt, resp in zip(rt_list, resp_list) if resp in [1,3,5]]
        incorrect_rt = [rt for rt, resp in zip(rt_list, resp_list) if resp in [2,4,6]]
        if correct_rt and incorrect_rt:
            return np.mean(incorrect_rt) - np.mean(correct_rt)
        return np.nan

    # ------------------ ì‹œì‘ ë³¸ë¬¸ ------------------
    df = df.copy()
    print("\n=== ì „ì²˜ë¦¬ ì‹œì‘ ===")

    # Age ë³€í™˜
    print("Age ë³€í™˜ ì¤‘...")
    df = convert_age_features(df, col="Age")

    

    # ==================== B ê´€ë ¨ íŒŒìƒë³€ìˆ˜ (B.py + B2.py í†µí•©) ====================
    
    # B1 ê²€ì‚¬
    print("\nB1 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if any(c in df.columns for c in ["B1-1", "B1-2", "B1-3"]):
        df['B1_1_list'] = df['B1-1'].apply(parse_list_column) if 'B1-1' in df.columns else [[] for _ in range(len(df))]
        df['B1_2_list'] = df['B1-2'].apply(parse_list_column) if 'B1-2' in df.columns else [[] for _ in range(len(df))]
        df['B1_3_list'] = df['B1-3'].apply(parse_list_column) if 'B1-3' in df.columns else [[] for _ in range(len(df))]

        df['b1_acc'] = df['B1_1_list'].apply(lambda x: sum([1 for i in x if i == 1]) / len(x) if len(x) > 0 else np.nan)
        df['b1_rt_mean'] = df['B1_2_list'].apply(safe_mean)
        df['b1_rt_std'] = df['B1_2_list'].apply(safe_std)

        df['b1_change_correct_cnt'] = df['B1_3_list'].apply(lambda x: sum([1 for i in x if i == 1]))
        df['b1_change_incorrect_cnt'] = df['B1_3_list'].apply(lambda x: sum([1 for i in x if i == 2]))
        df['b1_nonchange_correct_cnt'] = df['B1_3_list'].apply(lambda x: sum([1 for i in x if i == 3]))
        df['b1_nonchange_incorrect_cnt'] = df['B1_3_list'].apply(lambda x: sum([1 for i in x if i == 4]))

    # B2 ê²€ì‚¬
    print("B2 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if any(c in df.columns for c in ["B2-1", "B2-2", "B2-3"]):
        df['B2_1_list'] = df['B2-1'].apply(parse_list_column) if 'B2-1' in df.columns else [[] for _ in range(len(df))]
        df['B2_2_list'] = df['B2-2'].apply(parse_list_column) if 'B2-2' in df.columns else [[] for _ in range(len(df))]
        df['B2_3_list'] = df['B2-3'].apply(parse_list_column) if 'B2-3' in df.columns else [[] for _ in range(len(df))]

        df['b2_acc'] = df['B2_1_list'].apply(lambda x: sum([1 for i in x if i == 1]) / len(x) if len(x) > 0 else np.nan)
        df['b2_rt_mean'] = df['B2_2_list'].apply(safe_mean)
        df['b2_rt_std'] = df['B2_2_list'].apply(safe_std)

        df['b2_change_correct_cnt'] = df['B2_3_list'].apply(lambda x: sum([1 for i in x if i == 1]))
        df['b2_change_incorrect_cnt'] = df['B2_3_list'].apply(lambda x: sum([1 for i in x if i == 2]))
        df['b2_nonchange_correct_cnt'] = df['B2_3_list'].apply(lambda x: sum([1 for i in x if i == 3]))
        df['b2_nonchange_incorrect_cnt'] = df['B2_3_list'].apply(lambda x: sum([1 for i in x if i == 4]))

    # # B3 ê²€ì‚¬
    print("B3 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if any(c in df.columns for c in ["B3-1", "B3-2"]):
        df['B3_1_list'] = df['B3-1'].apply(parse_list_column) if 'B3-1' in df.columns else [[] for _ in range(len(df))]
        df['B3_2_list'] = df['B3-2'].apply(parse_list_column) if 'B3-2' in df.columns else [[] for _ in range(len(df))]

        df['b3_acc'] = df['B3_1_list'].apply(lambda x: sum([1 for i in x if i == 1]) / len(x) if len(x) > 0 else np.nan)
        df['b3_rt_mean'] = df['B3_2_list'].apply(safe_mean)
        df['b3_rt_std'] = df['B3_2_list'].apply(safe_std)

    # B4 ê²€ì‚¬
    print("B4 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if any(c in df.columns for c in ["B4-1", "B4-2"]):
        df['B4_1_list'] = df['B4-1'].apply(parse_list_column) if 'B4-1' in df.columns else [[] for _ in range(len(df))]
        df['B4_2_list'] = df['B4-2'].apply(parse_list_column) if 'B4-2' in df.columns else [[] for _ in range(len(df))]

        df['b4_congruent_correct_cnt'] = df['B4_1_list'].apply(lambda x: sum([1 for i in x if i == 1]))
        df['b4_congruent_incorrect_cnt'] = df['B4_1_list'].apply(lambda x: sum([1 for i in x if i == 2]))
        df['b4_incongruent_correct_cnt'] = df['B4_1_list'].apply(lambda x: sum([1 for i in x if i in [3, 5]]))
        df['b4_incongruent_incorrect_cnt'] = df['B4_1_list'].apply(lambda x: sum([1 for i in x if i in [4, 6]]))
        df['b4_acc'] = df['B4_1_list'].apply(lambda x: (sum([1 for i in x if i in [1, 3, 5]]) / len(x)) if len(x) > 0 else np.nan)
        df['b4_rt_mean'] = df['B4_2_list'].apply(safe_mean)
        df['b4_rt_std'] = df['B4_2_list'].apply(safe_std)

        # ë°˜ì‘ì‹œê°„ ì°¨ì´ (ì •ë‹µ vs ì˜¤ë‹µ)
        df['b4_rt_diff_incorrect_minus_correct'] = df.apply(
            lambda row: rt_diff_correct_incorrect(row['B4_2_list'], row['B4_1_list']), axis=1
        )

        # ì¼ì¹˜/ë¶ˆì¼ì¹˜ ì¡°ê±´ë³„ ë°˜ì‘ì‹œê°„
        df['b4_rt_congruent_mean'] = df.apply(
            lambda r: mean_rt_by_codes(r['B4_1_list'], r['B4_2_list'], {1,2}), axis=1
        )
        df['b4_rt_incongruent_mean'] = df.apply(
            lambda r: mean_rt_by_codes(r['B4_1_list'], r['B4_2_list'], {3,4,5,6}), axis=1
        )

    # B5 ê²€ì‚¬
    print("B5 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if any(c in df.columns for c in ["B5-1", "B5-2"]):
        df['B5_1_list'] = df['B5-1'].apply(parse_list_column) if 'B5-1' in df.columns else [[] for _ in range(len(df))]
        df['B5_2_list'] = df['B5-2'].apply(parse_list_column) if 'B5-2' in df.columns else [[] for _ in range(len(df))]

        df['b5_acc'] = df['B5_1_list'].apply(lambda x: sum([1 for i in x if i == 1]) / len(x) if len(x) > 0 else np.nan)
        df['B5_mean_rt'] = df['B5_2_list'].apply(safe_mean)
        df['B5_std_rt'] = df['B5_2_list'].apply(safe_std)

    # # B6 ê²€ì‚¬
    print("B6 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if 'B6' in df.columns:
        df['B6_list'] = df['B6'].apply(parse_list_column)
        df['b6_acc'] = df['B6_list'].apply(lambda x: sum([1 for i in x if i == 1]) / len(x) if len(x) > 0 else np.nan)

    # B7 ê²€ì‚¬
    print("B7 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if 'B7' in df.columns:
        df['B7_list'] = df['B7'].apply(parse_list_column)
        df['b7_acc'] = df['B7_list'].apply(lambda x: sum([1 for i in x if i == 1]) / len(x) if len(x) > 0 else np.nan)

    # B8 ê²€ì‚¬
    print("B8 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if 'B8' in df.columns:
        df['B8_list'] = df['B8'].apply(parse_list_column)
        df['b8_acc'] = df['B8_list'].apply(lambda x: sum([1 for i in x if i == 1]) / len(x) if len(x) > 0 else np.nan)

    # B9 ê²€ì‚¬ (Signal Detection Theory)
    print("B9 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if all(c in df.columns for c in ['B9-1', 'B9-2', 'B9-3', 'B9-4', 'B9-5']):
        df['b9_aud_sensitivity'] = np.where(
            ((df['B9-1'] + df['B9-2']) > 0) & ((df['B9-3'] + df['B9-4']) > 0),
            stats.norm.ppf((df['B9-1'] + 0.5) / (df['B9-1'] + df['B9-2'] + 1)) - 
            stats.norm.ppf((df['B9-3'] + 0.5) / (df['B9-3'] + df['B9-4'] + 1)),
            np.nan
        )
        df['b9_aud_bias'] = np.where(
            ((df['B9-1'] + df['B9-2']) > 0) & ((df['B9-3'] + df['B9-4']) > 0),
            -0.5 * (stats.norm.ppf((df['B9-1'] + 0.5) / (df['B9-1'] + df['B9-2'] + 1)) + 
                    stats.norm.ppf((df['B9-3'] + 0.5) / (df['B9-3'] + df['B9-4'] + 1))),
            np.nan
        )
        df['b9_aud_hit_rate'] = df['B9-1'] / (df['B9-1'] + df['B9-2'])
        df['b9_aud_false_alarm_rate'] = df['B9-3'] / (df['B9-3'] + df['B9-4'])
        df['b9_vis_error_rate'] = df['B9-5'] / 32

    # B10 ê²€ì‚¬ (Signal Detection Theory)
    print("B10 ê²€ì‚¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    if all(c in df.columns for c in ['B10-1', 'B10-2', 'B10-3', 'B10-4', 'B10-5', 'B10-6']):
        df['b10_aud_sensitivity'] = np.where(
            ((df['B10-1'] + df['B10-2']) > 0) & ((df['B10-3'] + df['B10-4']) > 0),
            stats.norm.ppf((df['B10-1'] + 0.5) / (df['B10-1'] + df['B10-2'] + 1)) - 
            stats.norm.ppf((df['B10-3'] + 0.5) / (df['B10-3'] + df['B10-4'] + 1)),
            np.nan
        )
        df['b10_aud_bias'] = np.where(
            ((df['B10-1'] + df['B10-2']) > 0) & ((df['B10-3'] + df['B10-4']) > 0),
            -0.5 * (stats.norm.ppf((df['B10-1'] + 0.5) / (df['B10-1'] + df['B10-2'] + 1)) + 
                    stats.norm.ppf((df['B10-3'] + 0.5) / (df['B10-3'] + df['B10-4'] + 1))),
            np.nan
        )
        df['b10_aud_hit_rate'] = df['B10-1'] / (df['B10-1'] + df['B10-2'])
        df['b10_aud_false_alarm_rate'] = df['B10-3'] / (df['B10-3'] + df['B10-4'])
        df['b10_vis1_error_rate'] = df['B10-5'] / 52
        df['b10_vis2_accuracy'] = df['B10-6'] / 20

    # ==================== B ì ìˆ˜ íŒŒìƒë³€ìˆ˜ (B2.py ë¡œì§) ====================
    print("\nì ìˆ˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì¤‘...")

    # 1. ì‹œì•¼ê°ê²€ì‚¬ ì ìˆ˜ (B1+B2)
    if all(c in df.columns for c in ['B1_change_correct', 'B1_nonchange_correct', 
                                       'B2_change_correct', 'B2_nonchange_correct',
                                       'B1_3_list', 'B2_3_list']):
        df['b1b2_score'] = (
            df['B1_change_correct'] + df['B1_nonchange_correct'] +
            df['B2_change_correct'] + df['B2_nonchange_correct'] +
            df['B1_3_list'].apply(lambda x: len([i for i in x if i in [1, 3]])) +
            df['B2_3_list'].apply(lambda x: len([i for i in x if i in [1, 3]]))
        )

    # 2. ì‹ í˜¸ë“±ê²€ì‚¬ ì ìˆ˜ (B3) - ì •ë‹µì‹œ ë°˜ì‘ì†ë„ í‰ê· 
    if 'B3_1_list' in df.columns and 'B3_2_list' in df.columns:
        def get_correct_rt_mean(idx):
            correct_list = df.loc[idx, 'B3_1_list']
            rt_list = df.loc[idx, 'B3_2_list']
            if len(correct_list) == 0 or len(rt_list) == 0:
                return np.nan
            correct_rts = [rt_list[i] for i in range(min(len(correct_list), len(rt_list))) 
                          if correct_list[i] == 1]
            return np.mean(correct_rts) if len(correct_rts) > 0 else np.nan
        df['b3_score'] = df.index.map(get_correct_rt_mean)

    # 3. í™”ì‚´í‘œê²€ì‚¬ ì ìˆ˜ (B4)
    if 'B4_1_list' in df.columns:
        df['b4_congruent_total'] = df['b4_congruent_correct_cnt'] + df['b4_congruent_incorrect_cnt']
        df['b4_incongruent_total'] = df['b4_incongruent_correct_cnt'] + df['b4_incongruent_incorrect_cnt']
        df['b4_accuracy_diff'] = df['b4_congruent_correct_cnt'] - df['b4_incongruent_correct_cnt']
        
        if 'B4_incongruent_rt' in df.columns and 'B4_congruent_rt' in df.columns:
            df['b4_rt_diff'] = df['b4_rt_incongruent_mean'] - df['b4_rt_congruent_mean']

    # 4. ë„ë¡œì°¾ê¸°ê²€ì‚¬ ì ìˆ˜ (B5)
    if 'B5_1_list' in df.columns:
        df['b5_score'] = df['B5_1_list'].apply(lambda x: sum([1 for i in x if i == 1]))

    # 5. í‘œì§€íŒê²€ì‚¬ ì ìˆ˜ (B6, B7)
    if 'B6_list' in df.columns:
        df['b6_correct_cnt'] = df['B6_list'].apply(lambda x: sum([1 for i in x if i == 1]))
    if 'B7_list' in df.columns:
        df['b7_correct_cnt'] = df['B7_list'].apply(lambda x: sum([1 for i in x if i == 1]))

    # 6. ì¶”ì ê²€ì‚¬ ì ìˆ˜ (B8)
    if 'B8_list' in df.columns:
        df['b8_score'] = df['B8_list'].apply(lambda x: sum([1 for i in x if i == 1]))

    # 7. ë³µí•©ê¸°ëŠ¥ê²€ì‚¬A ì ìˆ˜ (B9)
    if all(c in df.columns for c in ['B9-1', 'B9-5']):
        df['b9_aud_correct_cnt'] = df['B9-1']
        df['b9_vis_correct_cnt'] = 32 - df['B9-5']

    # 8. ë³µí•©ê¸°ëŠ¥ê²€ì‚¬B ì ìˆ˜ (B10)
    if all(c in df.columns for c in ['B10-1', 'B10-5', 'B10-6']):
        df['b10_aud_correct_cnt'] = df['B10-1']
        df['b10_vis1_correct_cnt'] = 52 - df['B10-5']
        df['b10_vis2_correct_cnt'] = df['B10-6']

    

    print("\n=== ì „ì²˜ë¦¬ ì™„ë£Œ! ===")
    print("\nìƒì„±ëœ ì£¼ìš” ë³€ìˆ˜:")
    print("- B ê²€ì‚¬ ê¸°ë³¸ í†µê³„ëŸ‰ (accuracy, mean_rt, std_rt)")
    print("- B ê²€ì‚¬ ì„¸ë¶€ ì¹´ìš´íŠ¸ (correct/incorrect)")
    print("- B ê²€ì‚¬ ì ìˆ˜ íŒŒìƒë³€ìˆ˜ (score_B1_B2, score_B3, score_B5, score_B8 ë“±)")

    return df


# (ì •ë¦¬) ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ë³´ì¡° í•¨ìˆ˜ ì œê±°


# =========================================================
# ğŸ”¸ PrimaryKey ê¸°ì¤€ TestDate ë”•ì…”ë„ˆë¦¬ + ì›” ì°¨ì´ íŒŒìƒë³€ìˆ˜ (Aì™€ ë™ì¼ ê·œì¹™)
# =========================================================

def build_primarykey_testdate_dict(df, save_path="./model/primarykey_testdate_dict_b.json"):
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        print("âš ï¸ PrimaryKey or TestDate not found")
        return {}
    pk_date_dict = {}
    for pk, group in df.groupby('PrimaryKey'):
        pk_date_dict[str(pk)] = group['TestDate'].tolist()
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(pk_date_dict, f, ensure_ascii=False, indent=2)
        print(f"âœ… Saved: {save_path}")
    return pk_date_dict


def _parse_yyyymm(date_str):
    try:
        s = str(date_str)
        return pd.Timestamp(year=int(s[:4]), month=int(s[4:6]), day=1)
    except:
        return None


def _prev_month_diff(current_dt, prev_dt):
    return (current_dt.year - prev_dt.year) * 12 + (current_dt.month - prev_dt.month)


def calculate_prev_month_diff(row, pk_date_dict):
    pk = str(row.get('PrimaryKey', ''))
    current_date = row.get('TestDate')
    if not pk or pk not in pk_date_dict or not current_date:
        return 0
    current_dt = _parse_yyyymm(current_date)
    if current_dt is None:
        return 0
    prev_dates = []
    for d in pk_date_dict[pk]:
        dt = _parse_yyyymm(d)
        if dt and dt < current_dt:
            prev_dates.append(dt)
    if not prev_dates:
        return 0
    most_recent_prev = max(prev_dates)
    return _prev_month_diff(current_dt, most_recent_prev)


def calculate_avg_prev_month_diff(row, pk_date_dict):
    pk = str(row.get('PrimaryKey', ''))
    current_date = row.get('TestDate')
    if not pk or pk not in pk_date_dict or not current_date:
        return 0
    current_dt = _parse_yyyymm(current_date)
    if current_dt is None:
        return 0
    prev_dates = []
    for d in pk_date_dict[pk]:
        dt = _parse_yyyymm(d)
        if dt and dt < current_dt:
            prev_dates.append(dt)
    if not prev_dates:
        return 0
    diffs = [_prev_month_diff(current_dt, p) for p in prev_dates]
    return float(np.mean(diffs)) if diffs else 0


def add_primarykey_month_diff_features(df, pk_date_dict):
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        print("âš ï¸ PrimaryKey or TestDate not found, skipping...")
        return df
    df = df.copy()
    df['PK_prev_month_diff'] = df.apply(lambda row: calculate_prev_month_diff(row, pk_date_dict), axis=1)
    df['PK_avg_prev_month_diff'] = df.apply(lambda row: calculate_avg_prev_month_diff(row, pk_date_dict), axis=1)
    print("âœ… Added B: PK_prev_month_diff, PK_avg_prev_month_diff")
    return df

# === PrimaryKey ê³¼ê±° ë¼ë²¨ íˆìŠ¤í† ë¦¬ (Aì™€ ë™ì¼ ì‹œê·¸ë‹ˆì²˜ ì œê³µ) ===
import os, json
import pandas as pd

def build_primary_label_history(df, save_path: str | None = None):
    """PrimaryKeyë³„ ìµœëŒ€ ë¼ë²¨ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ê¸°ì¡´ ë°©ì‹: 1ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0)"""
    if 'PrimaryKey' not in df.columns or 'Label' not in df.columns:
        return {}
    hist = df.groupby('PrimaryKey')['Label'].max().astype(int).to_dict()
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump({str(k): int(v) for k, v in hist.items()}, f, ensure_ascii=False, indent=2)
    return hist

def add_primary_history_features(df: pd.DataFrame, primary_label_history: dict, out_col: str = 'primary_past_label') -> pd.DataFrame:
    """PrimaryKeyë³„ ìµœëŒ€ ë¼ë²¨ ë¶€ì—¬ (ê¸°ì¡´ ë°©ì‹)"""
    df = df.copy()
    if 'PrimaryKey' not in df.columns:
        df[out_col] = -1
        return df
    df[out_col] = df['PrimaryKey'].map(lambda pk: primary_label_history.get(pk, primary_label_history.get(str(pk), -1))).fillna(-1).astype(int)
    return df

def build_primary_label_history_with_date(df, save_path: str | None = None):
    """PrimaryKeyë³„ë¡œ TestDate ìˆœ ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ë‚ ì§œ ê¸°ë°˜)"""
    if 'PrimaryKey' not in df.columns or 'Label' not in df.columns or 'TestDate' not in df.columns:
        return {}
    hist = {}
    for pk, group in df.groupby('PrimaryKey'):
        # PrimaryKeyë³„ë¡œ TestDate ìˆœ ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸
        pk_list = [(int(row['TestDate']), int(row['Label'])) for _, row in group.iterrows()]
        pk_list.sort(key=lambda x: x[0])  # TestDate ìˆœ ì •ë ¬
        hist[str(pk)] = pk_list
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(hist, f, ensure_ascii=False, indent=2)
    return hist

def add_primary_history_features_with_date(df: pd.DataFrame, primary_label_history: dict, out_col: str = 'primary_past_label') -> pd.DataFrame:
    """ê° í–‰ì˜ TestDateë³´ë‹¤ ì´ì „ ì¤‘ ìµœì‹  TestDateì˜ ë¼ë²¨ ê°€ì ¸ì˜¤ê¸° (ë‚ ì§œ ê¸°ë°˜, ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ ë¹ ë¥¸ ì¡°íšŒ)"""
    df = df.copy()
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        df[out_col] = -1
        return df
    
    # PrimaryKeyë³„ ì¡°íšŒìš© ë”•ì…”ë„ˆë¦¬ ì¤€ë¹„
    pk_to_past_label = {}
    for pk_str, pk_list in primary_label_history.items():
        pk_to_past_label[pk_str] = pk_list  # ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸
    
    def get_prev_label_fast(row):
        pk = str(row.get('PrimaryKey', ''))
        current_date = int(row.get('TestDate', 0))
        if not pk or pk not in pk_to_past_label:
            return -1
        pk_list = pk_to_past_label[pk]
        # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ìµœê·¼ ì´ì „ ë‚ ì§œ ì°¾ê¸°
        prev_label = -1
        for td, label in pk_list:
            if td < current_date:
                prev_label = label
            else:
                break  # ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì´í›„ëŠ” ëª¨ë‘ current_date ì´ìƒ
        return prev_label
    
    df[out_col] = df.apply(get_prev_label_fast, axis=1).astype(int)
    return df


def build_label_pattern_history(df, save_path: str | None = None):
    """
    ì „ì²´ train ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ì—¬ PrimaryKeyë³„ë¡œ TestDate ìˆœì„œëŒ€ë¡œ Label ì‹œí€€ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
    
    Args:
        df: train DataFrame (PrimaryKey, TestDate, Label ì»¬ëŸ¼ í•„ìš”)
        save_path: ì €ì¥í•  ê²½ë¡œ (Noneì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ)
    
    Returns:
        dict: {PrimaryKey: [(TestDate, Label), ...]} í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
    """
    if 'PrimaryKey' not in df.columns or 'Label' not in df.columns or 'TestDate' not in df.columns:
        return {}
    
    hist = {}
    for pk, group in df.groupby('PrimaryKey'):
        # PrimaryKeyë³„ë¡œ TestDate ìˆœ ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸
        pk_list = [(int(row['TestDate']), int(row['Label'])) for _, row in group.iterrows()]
        pk_list.sort(key=lambda x: x[0])  # TestDate ìˆœ ì •ë ¬
        hist[str(pk)] = pk_list
    
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(hist, f, ensure_ascii=False, indent=2)
    
    return hist


def add_label_pattern_features(df: pd.DataFrame, label_pattern_history: dict, 
                                out_col_prefix: str = 'pattern') -> pd.DataFrame:
    """
    ê° í–‰ì— ëŒ€í•´ TestDate ì´ì „ ì‹œì ê¹Œì§€ì˜ 4ê°€ì§€ íŒ¨í„´ ì¶œí˜„ íšŸìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ íŒŒìƒë³€ìˆ˜ ìƒì„±
    
    íŒ¨í„´:
    - pattern_1to1: ì´ì „ ë¼ë²¨ 1 â†’ í˜„ì¬ ë¼ë²¨ 1
    - pattern_1to0: ì´ì „ ë¼ë²¨ 1 â†’ í˜„ì¬ ë¼ë²¨ 0
    - pattern_0to1: ì´ì „ ë¼ë²¨ 0 â†’ í˜„ì¬ ë¼ë²¨ 1
    - pattern_0to0: ì´ì „ ë¼ë²¨ 0 â†’ í˜„ì¬ ë¼ë²¨ 0
    
    Args:
        df: DataFrame (PrimaryKey, TestDate ì»¬ëŸ¼ í•„ìš”)
        label_pattern_history: build_label_pattern_historyë¡œ ìƒì„±í•œ ë”•ì…”ë„ˆë¦¬
        out_col_prefix: ì¶œë ¥ ì»¬ëŸ¼ëª… prefix (ê¸°ë³¸ 'pattern')
    
    Returns:
        DataFrame: 4ê°€ì§€ íŒ¨í„´ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
    """
    df = df.copy()
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        df[f'{out_col_prefix}_1to1'] = 0
        df[f'{out_col_prefix}_1to0'] = 0
        df[f'{out_col_prefix}_0to1'] = 0
        df[f'{out_col_prefix}_0to0'] = 0
        return df
    
    def count_patterns(row):
        pk = str(row.get('PrimaryKey', ''))
        current_date = int(row.get('TestDate', 0))
        
        if not pk or pk not in label_pattern_history:
            return 0, 0, 0, 0
        
        pk_list = label_pattern_history[pk]
        
        # í•´ë‹¹ TestDate ì´ì „ ì‹œì ë§Œ í•„í„°ë§
        prev_list = [(td, label) for td, label in pk_list if td < current_date]
        
        # ê³¼ê±° label ì´ë ¥ì´ 2ê°œ ë¯¸ë§Œì´ë©´ ëª¨ë“  íŒ¨í„´ 0
        if len(prev_list) < 2:
            return 0, 0, 0, 0
        
        # íŒ¨í„´ ì¹´ìš´íŠ¸
        pattern_1to1 = 0
        pattern_1to0 = 0
        pattern_0to1 = 0
        pattern_0to0 = 0
        
        for i in range(1, len(prev_list)):
            prev_label = prev_list[i-1][1]
            curr_label = prev_list[i][1]
            
            if prev_label == 1 and curr_label == 1:
                pattern_1to1 += 1
            elif prev_label == 1 and curr_label == 0:
                pattern_1to0 += 1
            elif prev_label == 0 and curr_label == 1:
                pattern_0to1 += 1
            elif prev_label == 0 and curr_label == 0:
                pattern_0to0 += 1
        
        return pattern_1to1, pattern_1to0, pattern_0to1, pattern_0to0
    
    patterns = df.apply(count_patterns, axis=1, result_type='expand')
    df[f'{out_col_prefix}_1to1'] = patterns[0].astype(int)
    df[f'{out_col_prefix}_1to0'] = patterns[1].astype(int)
    df[f'{out_col_prefix}_0to1'] = patterns[2].astype(int)
    df[f'{out_col_prefix}_0to0'] = patterns[3].astype(int)
    
    return df


def add_is_first_test_feature_b(df: pd.DataFrame, label_history_dict: dict = None, out_col: str = 'is_first_test') -> pd.DataFrame:
    """
    ê° í–‰ì— ëŒ€í•´ PrimaryKey ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ TestDate ì´ì „ì— ê³¼ê±° ì´ë ¥ì´ ìˆëŠ”ì§€ í™•ì¸ (Bìš©)
    - ì´ë ¥ ì—†ìŒ (ì²« ì‹œí—˜) = 1
    - ì´ë ¥ ìˆìŒ = 0
    
    Parameters:
    -----------
    df : pd.DataFrame
        PrimaryKey, TestDate ì»¬ëŸ¼ì„ í¬í•¨í•œ ë°ì´í„°í”„ë ˆì„
    label_history_dict : dict, optional
        {PrimaryKey: [(TestDate, Label), ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        ì—†ìœ¼ë©´ dfë¡œë¶€í„° ìë™ ìƒì„±
    out_col : str
        ì¶œë ¥ ì»¬ëŸ¼ëª… (ê¸°ë³¸: 'is_first_test')
    
    Returns:
    --------
    pd.DataFrame
        is_first_test ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        df[out_col] = -1
        return df
    
    # label_history_dictê°€ ì—†ìœ¼ë©´ í˜„ì¬ dfë¡œë¶€í„° ìƒì„±
    if label_history_dict is None:
        print(f"[INFO] label_history_dictê°€ ì—†ì–´ì„œ í˜„ì¬ ë°ì´í„°ë¡œë¶€í„° ìƒì„±í•©ë‹ˆë‹¤.")
        label_history_dict = {}
        
        # Label ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ëŒ€ì²´
        if 'Label' in df.columns:
            temp_df = df[['PrimaryKey', 'TestDate', 'Label']].copy()
        else:
            temp_df = df[['PrimaryKey', 'TestDate']].copy()
            temp_df['Label'] = 0
        
        temp_df['TestDate'] = pd.to_numeric(temp_df['TestDate'], errors='coerce').fillna(0).astype(int)
        temp_df = temp_df.sort_values(['PrimaryKey', 'TestDate'])
        
        for pk, group in temp_df.groupby('PrimaryKey'):
            pk_str = str(pk)
            label_history_dict[pk_str] = [
                (int(row['TestDate']), int(row.get('Label', 0))) 
                for _, row in group.iterrows()
            ]
    
    # PrimaryKeyë³„ ì¡°íšŒìš© ë”•ì…”ë„ˆë¦¬ ì¤€ë¹„
    pk_to_history = {}
    for pk_str, pk_list in label_history_dict.items():
        pk_to_history[pk_str] = pk_list  # ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸
    
    def check_is_first_test(row):
        """í˜„ì¬ TestDate ì´ì „ì— ì´ë ¥ì´ ìˆëŠ”ì§€ í™•ì¸"""
        pk = str(row.get('PrimaryKey', ''))
        current_date = int(row.get('TestDate', 0))
        
        if not pk or pk not in pk_to_history:
            return 1  # ì´ë ¥ ì—†ìŒ = ì²« ì‹œí—˜
        
        pk_list = pk_to_history[pk]
        
        # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ í˜„ì¬ ë‚ ì§œ ì´ì „ì— ê¸°ë¡ì´ ìˆëŠ”ì§€ í™•ì¸
        has_previous_record = False
        for td, label in pk_list:
            if td < current_date:
                has_previous_record = True
                break  # í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì²« ì‹œí—˜ì´ ì•„ë‹˜
        
        return 0 if has_previous_record else 1  # ì´ë ¥ ìˆìŒ=0, ì—†ìŒ=1
    
    df[out_col] = df.apply(check_is_first_test, axis=1).astype(int)
    
    return df


def add_holiday_season_feature(df: pd.DataFrame, out_col: str = 'has_holiday_season', months_ahead: int = 6) -> pd.DataFrame:
    """
    í˜„ì¬ TestDate ê¸°ì¤€ìœ¼ë¡œ 6ê°œì›” ì´ë‚´ì— 9ì›” ë˜ëŠ” 10ì›”ì´ ìˆëŠ”ì§€ í™•ì¸
    - 9ì›”/10ì›” í¬í•¨ = 1 (ì—°íœ´ ìˆìŒ)
    - 9ì›”/10ì›” ì—†ìŒ = 0 (ì—°íœ´ ì—†ìŒ)
    
    Parameters:
    -----------
    df : pd.DataFrame
        TestDate ì»¬ëŸ¼ì„ í¬í•¨í•œ ë°ì´í„°í”„ë ˆì„ (YYYYMM í˜•ì‹)
    out_col : str
        ì¶œë ¥ ì»¬ëŸ¼ëª… (ê¸°ë³¸: 'has_holiday_season')
    months_ahead : int
        í™•ì¸í•  ë¯¸ë˜ ì›” ìˆ˜ (ê¸°ë³¸: 6ê°œì›”)
    
    Returns:
    --------
    pd.DataFrame
        has_holiday_season ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    
    Examples:
    ---------
    TestDate=202007 â†’ 6ê°œì›” ì´ë‚´ ë²”ìœ„: 202007~202101 â†’ 202009, 202010 í¬í•¨ â†’ 1
    TestDate=202011 â†’ 6ê°œì›” ì´ë‚´ ë²”ìœ„: 202011~202105 â†’ ë²”ìœ„ ë‚´ ì—†ìŒ â†’ 0
    TestDate=202003 â†’ 6ê°œì›” ì´ë‚´ ë²”ìœ„: 202003~202009 â†’ 202009 í¬í•¨ â†’ 1
    """
    df = df.copy()
    
    if 'TestDate' not in df.columns:
        df[out_col] = -1
        return df
    
    def has_sep_or_oct_in_range(test_date):
        """ì£¼ì–´ì§„ TestDateë¡œë¶€í„° months_ahead ì´ë‚´ì— 9ì›” ë˜ëŠ” 10ì›”ì´ ìˆëŠ”ì§€ í™•ì¸"""
        try:
            test_date_int = int(test_date)
            if test_date_int <= 0:
                return -1
            
            # YYYYMM íŒŒì‹±
            year = test_date_int // 100
            month = test_date_int % 100
            
            if month < 1 or month > 12:
                return -1
            
            # í˜„ì¬ ì›”ë¶€í„° months_ahead ê°œì›”ê¹Œì§€ í™•ì¸
            for i in range(months_ahead + 1):
                check_month = month + i
                check_year = year
                
                # ì›”ì´ 12ë¥¼ ë„˜ìœ¼ë©´ ë…„ë„ ì¦ê°€
                while check_month > 12:
                    check_month -= 12
                    check_year += 1
                
                # 9ì›” ë˜ëŠ” 10ì›”ì¸ì§€ í™•ì¸
                if check_month == 9 or check_month == 10:
                    return 1
            
            return 0
        except:
            return -1
    
    df[out_col] = df['TestDate'].apply(has_sep_or_oct_in_range).astype(int)
    
    return df