import os
import json
import numpy as np
import pandas as pd
from functools import lru_cache




# =========================================================
# ğŸ”¸ ìµœì í™”ëœ Helper í•¨ìˆ˜ë“¤ (ë²¡í„°í™”)
# =========================================================

@lru_cache(maxsize=10000)
def parse_seq_cached(seq_str):
    """ìºì‹±ì„ í™œìš©í•œ ì‹œí€€ìŠ¤ íŒŒì‹± (ë°˜ë³µë˜ëŠ” íŒ¨í„´ ë¹ ë¥´ê²Œ ì²˜ë¦¬)"""
    if not seq_str or seq_str == 'nan' or seq_str == '':
        return []
    try:
        return [float(x.strip()) for x in seq_str.split(",") if x.strip()]
    except:
        return []


def vectorized_count_values(series, condition_func):
    """ë²¡í„°í™”ëœ ê°’ ì¹´ìš´íŠ¸ (ì¡°ê±´ í•¨ìˆ˜ ì ìš©)"""
    # ë¬¸ìì—´ì„ ë¨¼ì € ì²˜ë¦¬
    series_str = series.fillna("").astype(str)
    
    result = np.zeros(len(series_str), dtype=int)
    for idx, val in enumerate(series_str):
        if val:
            try:
                values = [float(x.strip()) for x in val.split(",") if x.strip()]
                result[idx] = sum(1 for v in values if condition_func(v))
            except:
                result[idx] = 0
    
    return result


def fast_parse_and_abs_mean(series):
    """ë¹ ë¥¸ ì ˆëŒ€ê°’ í‰ê·  ê³„ì‚°"""
    result = np.full(len(series), np.nan)
    series_str = series.fillna("").astype(str)
    
    for idx, val in enumerate(series_str):
        if val and val != '':
            try:
                values = [float(x.strip()) for x in val.split(",") if x.strip()]
                if values:
                    result[idx] = np.mean(np.abs(values))
            except:
                pass
    
    return result


def fast_reaction_direction(series):
    """ë¹ ë¥¸ ë°˜ì‘ ë°©í–¥ ê³„ì‚°"""
    result = np.full(len(series), 0.5)
    series_str = series.fillna("").astype(str)
    
    for idx, val in enumerate(series_str):
        if val and val != '':
            try:
                values = [float(x.strip()) for x in val.split(",") if x.strip()]
                if values:
                    pos_count = sum(1 for v in values if v > 0)
                    neg_count = sum(1 for v in values if v < 0)
                    if pos_count > neg_count:
                        result[idx] = 1
                    elif neg_count > pos_count:
                        result[idx] = 0
            except:
                pass
    
    return result


def fast_diff_resp_match(df, diff_col, resp_col, name_prefix):
    """ìµœì í™”ëœ ë‚œì´ë„-ì‘ë‹µ ë§¤ì¹­"""
    if (diff_col not in df.columns) or (resp_col not in df.columns):
        return
    
    speed1_ones = np.zeros(len(df), dtype=int)
    speed2_ones = np.zeros(len(df), dtype=int)
    speed3_ones = np.zeros(len(df), dtype=int)
    
    diff_str = df[diff_col].fillna("").astype(str)
    resp_str = df[resp_col].fillna("").astype(str)
    
    for idx in range(len(df)):
        try:
            diffs = [int(float(x.strip())) for x in diff_str.iloc[idx].split(",") if x.strip()]
            resps = [int(float(x.strip())) for x in resp_str.iloc[idx].split(",") if x.strip()]
            L = min(len(diffs), len(resps))
            
            for i in range(L):
                if resps[i] == 1:
                    if diffs[i] == 1:
                        speed1_ones[idx] += 1
                    elif diffs[i] == 2:
                        speed2_ones[idx] += 1
                    elif diffs[i] == 3:
                        speed3_ones[idx] += 1
        except:
            pass
    
    df[f"{name_prefix}_speed1_correct_cnt"] = speed1_ones
    df[f"{name_prefix}_speed2_correct_cnt"] = speed2_ones
    df[f"{name_prefix}_speed3_correct_cnt"] = speed3_ones


# =========================================================
# ğŸ”¸ ìƒˆë¡œìš´ íŒŒìƒë³€ìˆ˜ìš© í—¬í¼ í•¨ìˆ˜ë“¤
# =========================================================

def parse_list_string(list_str):
    """ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ì •ìˆ˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if pd.isna(list_str) or list_str == "" or list_str == "nan":
        return []
    try:
        return [int(float(x.strip())) for x in str(list_str).split(",") if x.strip()]
    except:
        return []


def count_diff_indices(list1_str, list2_str):
    """ë‘ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°’ì´ ë‹¤ë¥¸ ì¸ë±ìŠ¤ì˜ ê°œìˆ˜"""
    list1 = parse_list_string(list1_str)
    list2 = parse_list_string(list2_str)
    
    if not list1 or not list2:
        return 0
    
    min_len = min(len(list1), len(list2))
    diff_count = 0
    
    for i in range(min_len):
        if list1[i] != list2[i]:
            diff_count += 1
    
    return diff_count


def count_diff_indices_with_condition(list1_str, list2_str, condition_str, condition_value):
    """ë‘ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°’ì´ ë‹¤ë¥¸ ì¸ë±ìŠ¤ ì¤‘ì—ì„œ conditionì—ì„œ íŠ¹ì • ê°’ì„ ê°€ì§„ ì¸ë±ìŠ¤ì˜ ê°œìˆ˜"""
    list1 = parse_list_string(list1_str)
    list2 = parse_list_string(list2_str)
    condition = parse_list_string(condition_str)
    
    if not list1 or not list2 or not condition:
        return 0
    
    min_len = min(len(list1), len(list2), len(condition))
    count = 0
    
    for i in range(min_len):
        if list1[i] != list2[i] and condition[i] == condition_value:
            count += 1
    
    return count


def count_diff_indices_with_conditions(list1_str, list2_str, condition1_str, condition2_str, condition1_value, condition2_value):
    """ë‘ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°’ì´ ë‹¤ë¥¸ ì¸ë±ìŠ¤ ì¤‘ì—ì„œ ë‘ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì¸ë±ìŠ¤ì˜ ê°œìˆ˜"""
    list1 = parse_list_string(list1_str)
    list2 = parse_list_string(list2_str)
    condition1 = parse_list_string(condition1_str)
    condition2 = parse_list_string(condition2_str)
    
    if not list1 or not list2 or not condition1 or not condition2:
        return 0
    
    min_len = min(len(list1), len(list2), len(condition1), len(condition2))
    count = 0
    
    for i in range(min_len):
        if list1[i] != list2[i] and condition1[i] == condition1_value and condition2[i] == condition2_value:
            count += 1
    
    return count


def count_consecutive_diff_indices(list1_str, list2_str):
    """ë‘ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°’ì´ ë‹¤ë¥¸ ì—°ì†ëœ ì¸ë±ìŠ¤ ê·¸ë£¹ì˜ ê°œìˆ˜"""
    list1 = parse_list_string(list1_str)
    list2 = parse_list_string(list2_str)
    
    if not list1 or not list2:
        return 0
    
    min_len = min(len(list1), len(list2))
    consecutive_groups = 0
    in_consecutive = False
    
    for i in range(min_len):
        if list1[i] != list2[i]:
            if not in_consecutive:
                consecutive_groups += 1
                in_consecutive = True
        else:
            in_consecutive = False
    
    return consecutive_groups


def count_condition_response(cond1_str, cond2_str, response_str, cond1_value, cond2_value, response_value):
    """ì¡°ê±´ 1, ì¡°ê±´ 2ê°€ íŠ¹ì • ê°’ì¼ ë•Œ ì‘ë‹µì´ íŠ¹ì • ê°’ì¸ ê²½ìš°ì˜ ê°œìˆ˜"""
    cond1 = parse_list_string(cond1_str)
    cond2 = parse_list_string(cond2_str)
    response = parse_list_string(response_str)
    
    if not cond1 or not cond2 or not response:
        return 0
    
    min_len = min(len(cond1), len(cond2), len(response))
    count = 0
    
    for i in range(min_len):
        if cond1[i] == cond1_value and cond2[i] == cond2_value and response[i] == response_value:
            count += 1
    
    return count


def count_condition_values(condition_str, response_str, condition_values, response_value):
    """ì¡°ê±´ì´ íŠ¹ì • ê°’ë“¤ ì¤‘ í•˜ë‚˜ì¼ ë•Œ ì‘ë‹µì´ íŠ¹ì • ê°’ì¸ ê²½ìš°ì˜ ê°œìˆ˜"""
    condition = parse_list_string(condition_str)
    response = parse_list_string(response_str)
    
    if not condition or not response:
        return 0
    
    min_len = min(len(condition), len(response))
    count = 0
    
    for i in range(min_len):
        if condition[i] in condition_values and response[i] == response_value:
            count += 1
    
    return count


# (ì œê±°) CNN íŠ¹ì§• ì¶”ì¶œ ê´€ë ¨ í•¨ìˆ˜ ì „ë¶€ ì‚­ì œ


# =========================================================
# ğŸ”¸ PrimaryKey ê¸°ì¤€ TestDate ë”•ì…”ë„ˆë¦¬ ìƒì„± ë° ì‚¬ìš©
# =========================================================

def build_primarykey_testdate_dict(df, save_path="./model/primarykey_testdate_dict.json"):
    """
    PrimaryKey ê¸°ì¤€ TestDate ë”•ì…”ë„ˆë¦¬ ìƒì„±
    - Key: PrimaryKey
    - Value: í•´ë‹¹ PrimaryKeyì˜ ëª¨ë“  TestDate ë¦¬ìŠ¤íŠ¸
    """
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        print("âš ï¸ PrimaryKey or TestDate not found")
        return {}
    
    pk_date_dict = {}
    for pk, group in df.groupby('PrimaryKey'):
        dates = group['TestDate'].tolist()
        pk_date_dict[str(pk)] = dates
    
    print(f"âœ… PrimaryKey-TestDate dictionary built: {len(pk_date_dict):,} keys")
    
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(pk_date_dict, f, ensure_ascii=False, indent=2)
        print(f"âœ… Saved: {save_path}")
    
    return pk_date_dict


def load_primarykey_testdate_dict(load_path="./model/primarykey_testdate_dict.json"):
    """PrimaryKey-TestDate ë”•ì…”ë„ˆë¦¬ ë¡œë“œ"""
    if not os.path.exists(load_path):
        print(f"âš ï¸ PrimaryKey-TestDate dictionary not found")
        return {}
    
    with open(load_path, 'r', encoding='utf-8') as f:
        pk_date_dict = json.load(f)
    
    print(f"âœ… PrimaryKey-TestDate dictionary loaded: {len(pk_date_dict):,} keys")
    return pk_date_dict


def calculate_prev_month_diff(row, pk_date_dict):
    """
    í˜„ì¬ ì‹œì ë³´ë‹¤ ì´ì „ ì‹œì ê³¼ì˜ ì›” ì°¨ì´ ê³„ì‚°
    - PrimaryKeyì˜ TestDate ë¦¬ìŠ¤íŠ¸ì—ì„œ í˜„ì¬ ì‹œì ë³´ë‹¤ ì´ì „ì¸ ë‚ ì§œë“¤ë§Œ ì°¾ê¸°
    - ì´ì „ ì‹œì ì´ ìˆìœ¼ë©´: (í˜„ì¬ ì‹œì  - ìµœê·¼ ì´ì „ ì‹œì ) ì˜ ì›” ì°¨ì´
    - ì´ì „ ì‹œì ì´ ì—†ìœ¼ë©´: 0 (ì²« ë²ˆì§¸ ì‹œì )
    - PrimaryKeyê°€ ì—†ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´: 0
    """
    pk = str(row.get('PrimaryKey', ''))
    current_date = row.get('TestDate')
    
    # PrimaryKeyê°€ ì—†ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì— ì—†ê±°ë‚˜ TestDateê°€ ì—†ìœ¼ë©´ 0 ë°˜í™˜
    if not pk or pk == 'nan' or pk not in pk_date_dict or not current_date:
        return 0
    
    # PrimaryKeyì˜ ëª¨ë“  TestDate ë¦¬ìŠ¤íŠ¸
    all_dates = pk_date_dict[pk]
    
    # YYYYMM í˜•ì‹ì„ datetimeìœ¼ë¡œ ë³€í™˜
    def parse_date(date_str):
        try:
            date_str = str(date_str)
            year = int(date_str[:4])
            month = int(date_str[4:6])
            return pd.Timestamp(year=year, month=month, day=1)
        except:
            return None
    
    current_dt = parse_date(current_date)
    if current_dt is None:
        return -1
    
    # ì´ì „ ì‹œì ë“¤ë§Œ í•„í„°ë§
    prev_dates = []
    for d in all_dates:
        d_dt = parse_date(d)
        if d_dt and d_dt < current_dt:
            prev_dates.append(d_dt)
    
    # ì´ì „ ì‹œì ì´ ì—†ìœ¼ë©´ 0 (ì²« ë²ˆì§¸ ì‹œì )
    if not prev_dates:
        return 0
    
    # ê°€ì¥ ê°€ê¹Œìš´ ì´ì „ ì‹œì ê³¼ì˜ ì°¨ì´
    most_recent_prev = max(prev_dates)
    month_diff = (current_dt.year - most_recent_prev.year) * 12 + (current_dt.month - most_recent_prev.month)
    
    return month_diff


def calculate_avg_prev_month_diff(row, pk_date_dict):
    """
    ì´ì „ ì‹œì ë“¤ê³¼ì˜ í‰ê·  ì›” ì°¨ì´ ê³„ì‚°
    - PrimaryKeyê°€ ì—†ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´: 0
    """
    pk = str(row.get('PrimaryKey', ''))
    current_date = row.get('TestDate')
    
    # PrimaryKeyê°€ ì—†ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì— ì—†ê±°ë‚˜ TestDateê°€ ì—†ìœ¼ë©´ 0 ë°˜í™˜
    if not pk or pk == 'nan' or pk not in pk_date_dict or not current_date:
        return 0
    
    all_dates = pk_date_dict[pk]
    
    def parse_date(date_str):
        try:
            date_str = str(date_str)
            year = int(date_str[:4])
            month = int(date_str[4:6])
            return pd.Timestamp(year=year, month=month, day=1)
        except:
            return None
    
    current_dt = parse_date(current_date)
    if current_dt is None:
        return 0
    
    # ì´ì „ ì‹œì ë“¤ë§Œ í•„í„°ë§
    prev_dates = []
    for d in all_dates:
        d_dt = parse_date(d)
        if d_dt and d_dt < current_dt:
            prev_dates.append(d_dt)
    
    # ì´ì „ ì‹œì ì´ ì—†ìœ¼ë©´ 0 (ì²« ë²ˆì§¸ ì‹œì )
    if not prev_dates:
        return 0
    
    # ëª¨ë“  ì´ì „ ì‹œì ê³¼ì˜ í‰ê·  ì›” ì°¨ì´
    month_diffs = []
    for prev_dt in prev_dates:
        month_diff = (current_dt.year - prev_dt.year) * 12 + (current_dt.month - prev_dt.month)
        month_diffs.append(month_diff)
    
    return np.mean(month_diffs)


def add_primarykey_month_diff_features(df, pk_date_dict):
    """
    PrimaryKey ê¸°ì¤€ ì´ì „ ì‹œì ê³¼ì˜ ì›” ì°¨ì´ íŒŒìƒë³€ìˆ˜ ì¶”ê°€
    """
    print("ğŸ”§ Adding PrimaryKey month difference features...")
    
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        print("âš ï¸ PrimaryKey or TestDate not found, skipping...")
        return df
    
    # ìµœê·¼ ì´ì „ ì‹œì ê³¼ì˜ ì›” ì°¨ì´
    df['PK_prev_month_diff'] = df.apply(lambda row: calculate_prev_month_diff(row, pk_date_dict), axis=1)
    
    # í‰ê·  ì´ì „ ì‹œì ê³¼ì˜ ì›” ì°¨ì´
    df['PK_avg_prev_month_diff'] = df.apply(lambda row: calculate_avg_prev_month_diff(row, pk_date_dict), axis=1)
    
    print(f"âœ… Added 2 PrimaryKey month difference features")
    
    return df


# =========================================================
# ğŸ”¸ ìµœì í™”ëœ ë©”ì¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
# =========================================================

def preprocess_a_features(df, use_cnn=True, rt_stats=None, use_a3_advanced=True, use_a4_advanced=True, use_a5_advanced=True, use_a9_advanced=True, pk_date_dict=None):
    """
    ìµœì í™”ëœ A ê²€ì‚¬ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ë²¡í„°í™” ë° ìºì‹± í™œìš©)
    """
    import time
    
    df = df.copy()
    
    print("\nâš¡ Fast preprocessing started...")
    t_start = time.time()
    
    # Age ë³€í™˜ (ë²¡í„°í™” ê°€ëŠ¥)
    if 'Age' in df.columns:
        def convert_age_vec(val):
            if pd.isna(val):
                return np.nan
            s = str(val).strip()
            if not s:
                return np.nan
            try:
                base = int(s[:-1])
                return base if s[-1] == "a" else base + 5
            except:
                try:
                    return int(s)
                except:
                    return np.nan
        
        df['Age_num'] = df['Age'].apply(convert_age_vec)
    
    # ìŒìˆ˜ ì¹´ìš´íŠ¸ (ë²¡í„°í™”)
    minus_columns = ["A1-4", "A2-4"]
    for col in minus_columns:
        if col in df.columns:
            new_name = f"{col.replace('-', '_')}_neg_count"
            df[new_name] = vectorized_count_values(df[col], lambda v: v < 0)
    
    # ì‘ë‹µ 1 ì¹´ìš´íŠ¸ (ë²¡í„°í™”)
    ones_columns = ["A1-3", "A2-3", "A3-6", "A3-5", "A4-3", "A4-4", "A5-2", "A5-3"]
    for col in ones_columns:
        if col in df.columns:
            new_name = f"{col.replace('-', '_')}_one_count"
            df[new_name] = vectorized_count_values(df[col], lambda v: v == 1)
    
    # A1 / A2 ë‚œì´ë„-ì‘ë‹µ ë§¤ì¹­ (ìµœì í™”)
    fast_diff_resp_match(df, "A1-2", "A1-3", "A1_2")
    fast_diff_resp_match(df, "A2-1", "A2-3", "A2_1")
    fast_diff_resp_match(df, "A2-2", "A2-3", "A2_2")
    
    # ë°˜ì‘ì†ë„ ê´€ë ¨ íŒŒìƒë³€ìˆ˜ (ìµœì í™”)
    if rt_stats is not None:
        rt_columns = ["A1-4", "A2-4", "A3-7", "A4-5"]
        created_count = 0
        
        for col in rt_columns:
            if col in df.columns:
                train_abs_mean = rt_stats.get(col, 0.0)
                if train_abs_mean != 0.0:
                    # ì ˆëŒ€ê°’ í‰ê·  (ìµœì í™”)
                    row_abs_means = fast_parse_and_abs_mean(df[col])
                    ratio_col = f"{col.replace('-', '_')}_abs_mean_ratio"
                    dir_col = f"{col.replace('-', '_')}_reaction_dir"
                    df[ratio_col] = (row_abs_means / train_abs_mean).astype(float)
                    df[ratio_col] = df[ratio_col].fillna(1.0)
                    df[dir_col] = fast_reaction_direction(df[col])
                    
                    created_count += 1
        
        print(f"âœ… Reaction time features: {created_count} features")
    
 
    
    # PrimaryKey ê¸°ì¤€ ì›” ì°¨ì´ íŒŒìƒë³€ìˆ˜ ì¶”ê°€
    if pk_date_dict is not None:
        t_pk = time.time()
        df = add_primarykey_month_diff_features(df, pk_date_dict)
        print(f"â±ï¸ PK month diff time: {time.time()-t_pk:.2f}s")
    else:
        print("â„¹ï¸ PrimaryKey month difference features disabled")
    
    print(f"â±ï¸ Total preprocessing time: {time.time()-t_start:.2f}s")
    
    return df


# =========================================================
# ğŸ”¸ ë°˜ì‘ì†ë„ í†µê³„ (ìµœì í™”)
# =========================================================

def build_reaction_time_stats_fast(df, save_path="./model/reaction_time_stats.json"):
    """ìµœì í™”ëœ ë°˜ì‘ì†ë„ í†µê³„ ìƒì„±"""
    rt_columns = ["A1-4", "A2-4", "A3-7", "A4-5"]
    rt_stats = {}
    
    for col in rt_columns:
        if col in df.columns:
            # ë²¡í„°í™”ëœ ì ˆëŒ€ê°’ í‰ê·  ê³„ì‚°
            abs_means = fast_parse_and_abs_mean(df[col])
            overall_mean = np.nanmean(abs_means)
            rt_stats[col] = float(overall_mean) if not np.isnan(overall_mean) else 0.0
            print(f"   {col}: abs_mean = {rt_stats[col]:.4f}")
        else:
            rt_stats[col] = 0.0
    
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(rt_stats, f, ensure_ascii=False, indent=2)
        print(f"âœ… Reaction time stats saved")
    
    return rt_stats


def load_reaction_time_stats(load_path="./model/reaction_time_stats.json"):
    if not os.path.exists(load_path):
        print(f"âš ï¸ Reaction time stats not found")
        return {"A1-4": 0.0, "A2-4": 0.0, "A3-7": 0.0, "A4-5": 0.0}
    
    with open(load_path, 'r', encoding='utf-8') as f:
        rt_stats = json.load(f)
    
    print(f"âœ… Reaction time stats loaded")
    return rt_stats


# === PrimaryKey ê³¼ê±° ë¼ë²¨ íˆìŠ¤í† ë¦¬ ===
import os, json
import pandas as pd

def _parse_yyyymm(date_str):
    try:
        s = str(date_str)
        return pd.Timestamp(year=int(s[:4]), month=int(s[4:6]), day=1)
    except:
        return None

def build_primary_label_history(df, save_path: str | None = None):
    """PrimaryKeyë³„ ìµœëŒ€ ë¼ë²¨ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ê¸°ì¡´ ë°©ì‹: 1ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0)"""
    if 'PrimaryKey' not in df.columns or 'Label' not in df.columns:
        return {}
    hist = df.groupby('PrimaryKey')['Label'].max().astype(int).to_dict()
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump({str(k): int(v) for k, v in hist.items()}, f, ensure_ascii=False, indent=2)
    return hist

def add_primary_history_features(df: pd.DataFrame, primary_label_history: dict, out_col: str = 'primary_past_label') -> pd.DataFrame:
    """PrimaryKeyë³„ ìµœëŒ€ ë¼ë²¨ ë¶€ì—¬ (ê¸°ì¡´ ë°©ì‹)"""
    df = df.copy()
    if 'PrimaryKey' not in df.columns:
        df[out_col] = -1
        return df
    df[out_col] = df['PrimaryKey'].map(lambda pk: primary_label_history.get(pk, primary_label_history.get(str(pk), -1))).fillna(-1).astype(int)
    return df

def build_primary_label_history_with_date(df, save_path: str | None = None):
    """PrimaryKeyë³„ë¡œ TestDate ìˆœ ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ë‚ ì§œ ê¸°ë°˜)"""
    if 'PrimaryKey' not in df.columns or 'Label' not in df.columns or 'TestDate' not in df.columns:
        return {}
    hist = {}
    for pk, group in df.groupby('PrimaryKey'):
        # PrimaryKeyë³„ë¡œ TestDate ìˆœ ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸
        pk_list = [(int(row['TestDate']), int(row['Label'])) for _, row in group.iterrows()]
        pk_list.sort(key=lambda x: x[0])  # TestDate ìˆœ ì •ë ¬
        hist[str(pk)] = pk_list
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(hist, f, ensure_ascii=False, indent=2)
    return hist

def add_primary_history_features_with_date(df: pd.DataFrame, primary_label_history: dict, out_col: str = 'primary_past_label') -> pd.DataFrame:
    """ê° í–‰ì˜ TestDateë³´ë‹¤ ì´ì „ ì¤‘ ìµœì‹  TestDateì˜ ë¼ë²¨ ê°€ì ¸ì˜¤ê¸° (ë‚ ì§œ ê¸°ë°˜, ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ ë¹ ë¥¸ ì¡°íšŒ)"""
    df = df.copy()
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        df[out_col] = -1
        return df
    
    # PrimaryKeyë³„ ì¡°íšŒìš© ë”•ì…”ë„ˆë¦¬ ì¤€ë¹„
    pk_to_past_label = {}
    for pk_str, pk_list in primary_label_history.items():
        pk_to_past_label[pk_str] = pk_list  # ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸
    
    def get_prev_label_fast(row):
        pk = str(row.get('PrimaryKey', ''))
        current_date = int(row.get('TestDate', 0))
        if not pk or pk not in pk_to_past_label:
            return -1
        pk_list = pk_to_past_label[pk]
        # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ìµœê·¼ ì´ì „ ë‚ ì§œ ì°¾ê¸°
        prev_label = -1
        for td, label in pk_list:
            if td < current_date:
                prev_label = label
            else:
                break  # ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì´í›„ëŠ” ëª¨ë‘ current_date ì´ìƒ
        return prev_label
    
    df[out_col] = df.apply(get_prev_label_fast, axis=1).astype(int)
    return df


def build_b_previous_label_dict_for_a(df_b, save_path: str | None = None):
    """
    B ë°ì´í„°ì—ì„œ PrimaryKeyë³„ ìµœëŒ€ ë¼ë²¨ ë”•ì…”ë„ˆë¦¬ ìƒì„± (any ë°©ì‹: 1ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0)
    A ë°ì´í„°ì—ì„œ Bì˜ ë¼ë²¨ì„ ì°¾ê¸° ìœ„í•´ ì‚¬ìš©
    
    Args:
        df_b: B ë°ì´í„° DataFrame (PrimaryKey, Label ì»¬ëŸ¼ í•„ìš”)
        save_path: ì €ì¥í•  ê²½ë¡œ (Noneì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ)
    
    Returns:
        dict: {PrimaryKey: max_label} í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬ (any ë°©ì‹)
    """
    if 'PrimaryKey' not in df_b.columns or 'Label' not in df_b.columns:
        return {}
    
    # PrimaryKeyë³„ ìµœëŒ€ ë¼ë²¨ (1ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0)
    hist = df_b.groupby('PrimaryKey')['Label'].max().astype(int).to_dict()
    hist = {str(k): int(v) for k, v in hist.items()}
    
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(hist, f, ensure_ascii=False, indent=2)
    
    return hist


def add_b_previous_label_to_a(df_a: pd.DataFrame, b_label_history: dict, out_col: str = 'b_previous_label') -> pd.DataFrame:
    """
    A ë°ì´í„°ì— Bì˜ ë¼ë²¨ ì¶”ê°€ (any ë°©ì‹)
    - PrimaryKeyê°€ A, B ë‘˜ ë‹¤ì— ìˆëŠ” ê²½ìš°
    - Bì—ì„œ ë¼ë²¨ 1ì´ í•œ ë²ˆì´ë¼ë„ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0 (TestDate ì¡°ê±´ ì—†ìŒ)
    
    Args:
        df_a: A ë°ì´í„° DataFrame (PrimaryKey ì»¬ëŸ¼ í•„ìš”)
        b_label_history: build_b_previous_label_dict_for_aë¡œ ìƒì„±í•œ ë”•ì…”ë„ˆë¦¬ (any ë°©ì‹)
        out_col: ì¶œë ¥ ì»¬ëŸ¼ëª…
    
    Returns:
        DataFrame: out_col ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
    """
    df = df_a.copy()
    if 'PrimaryKey' not in df.columns:
        df[out_col] = -1
        return df
    
    # PrimaryKeyë³„ë¡œ Bì˜ ìµœëŒ€ ë¼ë²¨ ë§¤í•‘ (any ë°©ì‹)
    df[out_col] = df['PrimaryKey'].map(
        lambda pk: b_label_history.get(str(pk), b_label_history.get(pk, -1))
    ).fillna(-1).astype(int)
    
    return df


def add_month_prev_label_adjustment_feature(df_a: pd.DataFrame, primary_label_history: dict, 
                                             month_threshold=9, 
                                             short_interval_prob=0.9, 
                                             long_interval_prob=0.66,
                                             out_col: str = 'month_prev_label_adj') -> pd.DataFrame:
    """
    A ë°ì´í„°ì— ê°œì›” ìˆ˜ì™€ ì´ì „ ë¼ë²¨ ê¸°ë°˜ í™•ë¥  ê°’ ë¶€ì—¬ (í›„ì²˜ë¦¬ ëŒ€ì‹  ë³€ìˆ˜ë¡œ ìƒì„±)
    - ê° í–‰ì˜ PrimaryKeyì™€ TestDateë¡œ ë°”ë¡œ ì´ì „ ì‹œì  ì¡°íšŒ
    - ê°œì›” ìˆ˜ê°€ 9 ì´ì „ì´ë©´ short_interval_prob (0.9)
    - ê°œì›” ìˆ˜ê°€ 9 ì´ìƒì´ë©´ long_interval_prob (0.66)
    - ë§¤ì¹­ ì•ˆë˜ëŠ” ê²½ìš° -1
    
    Args:
        df_a: A ë°ì´í„° DataFrame (PrimaryKey, TestDate ì»¬ëŸ¼ í•„ìš”)
        primary_label_history: build_primary_label_history_with_dateë¡œ ìƒì„±í•œ ë”•ì…”ë„ˆë¦¬
                              {PrimaryKey: [(TestDate, Label), ...]} í˜•ì‹
        month_threshold: ê°œì›” ìˆ˜ ê¸°ì¤€ê°’ (ê¸°ë³¸ 9)
        short_interval_prob: ì§§ì€ ê°„ê²©ì¼ ë•Œ í™•ë¥  ê°’ (ê¸°ë³¸ 0.9)
        long_interval_prob: ê¸´ ê°„ê²©ì¼ ë•Œ í™•ë¥  ê°’ (ê¸°ë³¸ 0.66)
        out_col: ì¶œë ¥ ì»¬ëŸ¼ëª…
    
    Returns:
        DataFrame: out_col ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
    """
    df = df_a.copy()
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        df[out_col] = -1.0
        return df
    
    def yyyymm_to_months(yyyymm):
        """YYYYMM ì •ìˆ˜ë¥¼ ì›” ë‹¨ìœ„ ì •ìˆ˜ë¡œ ë³€í™˜"""
        try:
            year = int(yyyymm) // 100
            month = int(yyyymm) % 100
            return year * 12 + month
        except:
            return None
    
    def month_diff_yyyymm(a, b):
        """ë‘ YYYYMM(ì •ìˆ˜) ì‚¬ì´ì˜ ì›” ì°¨ì´ | a - b | ë°˜í™˜"""
        months_a = yyyymm_to_months(a)
        months_b = yyyymm_to_months(b)
        if months_a is None or months_b is None:
            return None
        return abs(months_a - months_b)
    
    def get_adjustment_value(row):
        pk = str(row.get('PrimaryKey', ''))
        current_date = int(row.get('TestDate', 0))
        
        if not pk or pk not in primary_label_history:
            return -1.0
        
        pk_list = primary_label_history[pk]
        
        # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë°”ë¡œ ì´ì „ ì‹œì  ì°¾ê¸°
        prev_date = None
        prev_label = None
        for td, label in pk_list:
            if td < current_date:
                prev_date = td
                prev_label = label
            else:
                break
        
        # ì´ì „ ì‹œì ì´ ì—†ìœ¼ë©´ -1
        if prev_date is None or prev_label is None:
            return -1.0
        
        # ì´ì „ ë¼ë²¨ì´ 0ì´ë©´ -1
        if prev_label == 0:
            return -1.0
        
        # ì´ì „ ë¼ë²¨ì´ 1ì¼ ë•Œë§Œ í™•ë¥  ê°’ ë¶€ì—¬
        # ê°œì›” ìˆ˜ ì°¨ì´ ê³„ì‚°
        month_diff = month_diff_yyyymm(current_date, prev_date)
        if month_diff is None:
            return -1.0
        
        # 9ê°œì›” ì´ì „ì´ë©´ 0.9, 9ê°œì›” ì´ìƒì´ë©´ 0.66
        if month_diff < month_threshold:
            return float(short_interval_prob)
        else:
            return float(long_interval_prob)
    
    df[out_col] = df.apply(get_adjustment_value, axis=1).astype(float)
    return df


def _ensure_testdate_int(value):
    """Convert TestDate value to integer YYYYMM format if possible."""
    if pd.isna(value):
        return None
    if isinstance(value, pd.Timestamp):
        return int(value.strftime("%Y%m"))
    if isinstance(value, str):
        value = value.strip()
        if not value:
            return None
    try:
        return int(value)
    except (ValueError, TypeError):
        try:
            ts = pd.to_datetime(value)
            return int(ts.strftime("%Y%m"))
        except Exception:
            return None


def build_label_pattern_history(df, save_path: str | None = None):
    """
    ì „ì²´ train ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ì—¬ PrimaryKeyë³„ë¡œ TestDate ìˆœì„œëŒ€ë¡œ Label ì‹œí€€ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
    
    Args:
        df: train DataFrame (PrimaryKey, TestDate, Label ì»¬ëŸ¼ í•„ìš”)
        save_path: ì €ì¥í•  ê²½ë¡œ (Noneì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ)
    
    Returns:
        dict: {PrimaryKey: [(TestDate, Label), ...]} í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
    """
    if 'PrimaryKey' not in df.columns or 'Label' not in df.columns or 'TestDate' not in df.columns:
        return {}
    
    hist = {}
    for pk, group in df.groupby('PrimaryKey'):
        pk_list = []
        for _, row in group.iterrows():
            td_int = _ensure_testdate_int(row['TestDate'])
            if td_int is None:
                continue
            pk_list.append((td_int, int(row['Label'])))
        pk_list.sort(key=lambda x: x[0])  # TestDate ìˆœ ì •ë ¬
        hist[str(pk)] = pk_list
    
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(hist, f, ensure_ascii=False, indent=2)
    
    return hist


def add_label_pattern_features(df: pd.DataFrame, label_pattern_history: dict, 
                                out_col_prefix: str = 'pattern') -> pd.DataFrame:
    """
    ê° í–‰ì— ëŒ€í•´ TestDate ì´ì „ ì‹œì ê¹Œì§€ì˜ 4ê°€ì§€ íŒ¨í„´ ì¶œí˜„ íšŸìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ íŒŒìƒë³€ìˆ˜ ìƒì„±
    
    íŒ¨í„´:
    - pattern_1to1: ì´ì „ ë¼ë²¨ 1 â†’ í˜„ì¬ ë¼ë²¨ 1
    - pattern_1to0: ì´ì „ ë¼ë²¨ 1 â†’ í˜„ì¬ ë¼ë²¨ 0
    - pattern_0to1: ì´ì „ ë¼ë²¨ 0 â†’ í˜„ì¬ ë¼ë²¨ 1
    - pattern_0to0: ì´ì „ ë¼ë²¨ 0 â†’ í˜„ì¬ ë¼ë²¨ 0
    
    Args:
        df: DataFrame (PrimaryKey, TestDate ì»¬ëŸ¼ í•„ìš”)
        label_pattern_history: build_label_pattern_historyë¡œ ìƒì„±í•œ ë”•ì…”ë„ˆë¦¬
        out_col_prefix: ì¶œë ¥ ì»¬ëŸ¼ëª… prefix (ê¸°ë³¸ 'pattern')
    
    Returns:
        DataFrame: 4ê°€ì§€ íŒ¨í„´ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
    """
    df = df.copy()
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        df[f'{out_col_prefix}_1to1'] = 0
        df[f'{out_col_prefix}_1to0'] = 0
        df[f'{out_col_prefix}_0to1'] = 0
        df[f'{out_col_prefix}_0to0'] = 0
        return df
    
    def count_patterns(row):
        pk = str(row.get('PrimaryKey', ''))
        current_date = _ensure_testdate_int(row.get('TestDate', None))
        
        if not pk or pk not in label_pattern_history or current_date is None:
            return 0, 0, 0, 0
        
        pk_list = label_pattern_history[pk]
        
        # í•´ë‹¹ TestDate ì´ì „ ì‹œì ë§Œ í•„í„°ë§
        prev_list = [(td, label) for td, label in pk_list if td < current_date]
        
        # ê³¼ê±° label ì´ë ¥ì´ 2ê°œ ë¯¸ë§Œì´ë©´ ëª¨ë“  íŒ¨í„´ 0
        if len(prev_list) < 2:
            return 0, 0, 0, 0
        
        # íŒ¨í„´ ì¹´ìš´íŠ¸
        pattern_1to1 = 0
        pattern_1to0 = 0
        pattern_0to1 = 0
        pattern_0to0 = 0
        
        for i in range(1, len(prev_list)):
            prev_label = prev_list[i-1][1]
            curr_label = prev_list[i][1]
            
            if prev_label == 1 and curr_label == 1:
                pattern_1to1 += 1
            elif prev_label == 1 and curr_label == 0:
                pattern_1to0 += 1
            elif prev_label == 0 and curr_label == 1:
                pattern_0to1 += 1
            elif prev_label == 0 and curr_label == 0:
                pattern_0to0 += 1
        
        return pattern_1to1, pattern_1to0, pattern_0to1, pattern_0to0
    
    pattern_series = df.apply(count_patterns, axis=1)
    columns = [
        f'{out_col_prefix}_1to1',
        f'{out_col_prefix}_1to0',
        f'{out_col_prefix}_0to1',
        f'{out_col_prefix}_0to0',
    ]
    if pattern_series.empty:
        pattern_df = pd.DataFrame([], index=df.index, columns=columns)
    else:
        pattern_df = pd.DataFrame(list(pattern_series), index=df.index, columns=columns)

    for col in columns:
        df[col] = pattern_df.get(col, pd.Series(0, index=df.index)).fillna(0).astype(int)
    
    return df


def add_is_first_test_feature(df: pd.DataFrame, label_history_dict: dict = None, out_col: str = 'is_first_test') -> pd.DataFrame:
    """
    ê° í–‰ì— ëŒ€í•´ PrimaryKey ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ TestDate ì´ì „ì— ê³¼ê±° ì´ë ¥ì´ ìˆëŠ”ì§€ í™•ì¸
    - ì´ë ¥ ì—†ìŒ (ì²« ì‹œí—˜) = 1
    - ì´ë ¥ ìˆìŒ = 0
    
    Parameters:
    -----------
    df : pd.DataFrame
        PrimaryKey, TestDate ì»¬ëŸ¼ì„ í¬í•¨í•œ ë°ì´í„°í”„ë ˆì„
    label_history_dict : dict, optional
        {PrimaryKey: [(TestDate, Label), ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        ì—†ìœ¼ë©´ dfë¡œë¶€í„° ìë™ ìƒì„±
    out_col : str
        ì¶œë ¥ ì»¬ëŸ¼ëª… (ê¸°ë³¸: 'is_first_test')
    
    Returns:
    --------
    pd.DataFrame
        is_first_test ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    if 'PrimaryKey' not in df.columns or 'TestDate' not in df.columns:
        df[out_col] = -1
        return df
    
    # label_history_dictê°€ ì—†ìœ¼ë©´ í˜„ì¬ dfë¡œë¶€í„° ìƒì„±
    if label_history_dict is None:
        print(f"[INFO] label_history_dictê°€ ì—†ì–´ì„œ í˜„ì¬ ë°ì´í„°ë¡œë¶€í„° ìƒì„±í•©ë‹ˆë‹¤.")
        label_history_dict = {}
        
        # Label ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ëŒ€ì²´
        if 'Label' in df.columns:
            temp_df = df[['PrimaryKey', 'TestDate', 'Label']].copy()
        else:
            temp_df = df[['PrimaryKey', 'TestDate']].copy()
            temp_df['Label'] = 0
        
        temp_df['TestDate'] = pd.to_numeric(temp_df['TestDate'], errors='coerce').fillna(0).astype(int)
        temp_df = temp_df.sort_values(['PrimaryKey', 'TestDate'])
        
        for pk, group in temp_df.groupby('PrimaryKey'):
            pk_str = str(pk)
            label_history_dict[pk_str] = [
                (int(row['TestDate']), int(row.get('Label', 0))) 
                for _, row in group.iterrows()
            ]
    
    # PrimaryKeyë³„ ì¡°íšŒìš© ë”•ì…”ë„ˆë¦¬ ì¤€ë¹„
    pk_to_history = {}
    for pk_str, pk_list in label_history_dict.items():
        pk_to_history[pk_str] = pk_list  # ì •ë ¬ëœ (TestDate, Label) ë¦¬ìŠ¤íŠ¸
    
    def check_is_first_test(row):
        """í˜„ì¬ TestDate ì´ì „ì— ì´ë ¥ì´ ìˆëŠ”ì§€ í™•ì¸"""
        pk = str(row.get('PrimaryKey', ''))
        current_date = int(row.get('TestDate', 0))
        
        if not pk or pk not in pk_to_history:
            return 1  # ì´ë ¥ ì—†ìŒ = ì²« ì‹œí—˜
        
        pk_list = pk_to_history[pk]
        
        # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ í˜„ì¬ ë‚ ì§œ ì´ì „ì— ê¸°ë¡ì´ ìˆëŠ”ì§€ í™•ì¸
        has_previous_record = False
        for td, label in pk_list:
            if td < current_date:
                has_previous_record = True
                break  # í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì²« ì‹œí—˜ì´ ì•„ë‹˜
        
        return 0 if has_previous_record else 1  # ì´ë ¥ ìˆìŒ=0, ì—†ìŒ=1
    
    df[out_col] = df.apply(check_is_first_test, axis=1).astype(int)
    
    return df


def add_holiday_season_feature(df: pd.DataFrame, out_col: str = 'has_holiday_season', months_ahead: int = 6) -> pd.DataFrame:
    """
    í˜„ì¬ TestDate ê¸°ì¤€ìœ¼ë¡œ 6ê°œì›” ì´ë‚´ì— 9ì›” ë˜ëŠ” 10ì›”ì´ ìˆëŠ”ì§€ í™•ì¸
    - 9ì›”/10ì›” í¬í•¨ = 1 (ì—°íœ´ ìˆìŒ)
    - 9ì›”/10ì›” ì—†ìŒ = 0 (ì—°íœ´ ì—†ìŒ)
    
    Parameters:
    -----------
    df : pd.DataFrame
        TestDate ì»¬ëŸ¼ì„ í¬í•¨í•œ ë°ì´í„°í”„ë ˆì„ (YYYYMM í˜•ì‹)
    out_col : str
        ì¶œë ¥ ì»¬ëŸ¼ëª… (ê¸°ë³¸: 'has_holiday_season')
    months_ahead : int
        í™•ì¸í•  ë¯¸ë˜ ì›” ìˆ˜ (ê¸°ë³¸: 6ê°œì›”)
    
    Returns:
    --------
    pd.DataFrame
        has_holiday_season ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    
    Examples:
    ---------
    TestDate=202007 â†’ 6ê°œì›” ì´ë‚´ ë²”ìœ„: 202007~202101 â†’ 202009, 202010 í¬í•¨ â†’ 1
    TestDate=202011 â†’ 6ê°œì›” ì´ë‚´ ë²”ìœ„: 202011~202105 â†’ ë²”ìœ„ ë‚´ ì—†ìŒ â†’ 0
    TestDate=202003 â†’ 6ê°œì›” ì´ë‚´ ë²”ìœ„: 202003~202009 â†’ 202009 í¬í•¨ â†’ 1
    """
    df = df.copy()
    
    if 'TestDate' not in df.columns:
        df[out_col] = -1
        return df
    
    def has_sep_or_oct_in_range(test_date):
        """ì£¼ì–´ì§„ TestDateë¡œë¶€í„° months_ahead ì´ë‚´ì— 9ì›” ë˜ëŠ” 10ì›”ì´ ìˆëŠ”ì§€ í™•ì¸"""
        try:
            test_date_int = int(test_date)
            if test_date_int <= 0:
                return -1
            
            # YYYYMM íŒŒì‹±
            year = test_date_int // 100
            month = test_date_int % 100
            
            if month < 1 or month > 12:
                return -1
            
            # í˜„ì¬ ì›”ë¶€í„° months_ahead ê°œì›”ê¹Œì§€ í™•ì¸
            for i in range(months_ahead + 1):
                check_month = month + i
                check_year = year
                
                # ì›”ì´ 12ë¥¼ ë„˜ìœ¼ë©´ ë…„ë„ ì¦ê°€
                while check_month > 12:
                    check_month -= 12
                    check_year += 1
                
                # 9ì›” ë˜ëŠ” 10ì›”ì¸ì§€ í™•ì¸
                if check_month == 9 or check_month == 10:
                    return 1
            
            return 0
        except:
            return -1
    
    df[out_col] = df['TestDate'].apply(has_sep_or_oct_in_range).astype(int)
    
    return df


def add_a2_condition_reaction_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    A2 ì»¬ëŸ¼ë“¤ì˜ ì¡°ê±´ë³„, ë¶€í˜¸ë³„ ë°˜ì‘ì†ë„ í‰ê·  ê³„ì‚°
    
    A2-1: condition 1 (1=SLOW, 2=NORMAL, 3=FAST)
    A2-2: condition 2 (1=SLOW, 2=NORMAL, 3=FAST)
    A2-3: response (0=No, 1=Yes)
    A2-4: response time (+ / -)
    
    A2-3 == 1ì¸ trialë§Œ ì„ íƒí•˜ì—¬:
    - A2-1, A2-2 ê°ê°ì˜ ì¡°ê±´ë³„ (SLOW/NORMAL/FAST)
    - A2-4ì˜ ë¶€í˜¸ë³„ (ì–‘ìˆ˜/ìŒìˆ˜)
    - ë°˜ì‘ì†ë„ í‰ê·  ê³„ì‚°
    
    ìƒì„±ë˜ëŠ” ë³€ìˆ˜:
    - A2-1_SLOW_pos_mean, A2-1_SLOW_neg_mean
    - A2-1_NORMAL_pos_mean, A2-1_NORMAL_neg_mean
    - A2-1_FAST_pos_mean, A2-1_FAST_neg_mean
    - A2-2_SLOW_pos_mean, A2-2_SLOW_neg_mean
    - A2-2_NORMAL_pos_mean, A2-2_NORMAL_neg_mean
    - A2-2_FAST_pos_mean, A2-2_FAST_neg_mean
    
    Parameters:
    -----------
    df : pd.DataFrame
        A2-1, A2-2, A2-3, A2-4 ì»¬ëŸ¼ì„ í¬í•¨í•œ ë°ì´í„°í”„ë ˆì„
    
    Returns:
    --------
    pd.DataFrame
        12ê°œì˜ íŒŒìƒë³€ìˆ˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    # í•„ìš”í•œ ì»¬ëŸ¼ ì²´í¬
    required_cols = ['A2-1', 'A2-2', 'A2-3', 'A2-4']
    if not all(col in df.columns for col in required_cols):
        # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ëª¨ë“  íŒŒìƒë³€ìˆ˜ë¥¼ -1ë¡œ ì„¤ì •
        for cond_col in ['A2-1', 'A2-2']:
            for condition in ['SLOW', 'NORMAL', 'FAST']:
                for sign in ['pos', 'neg']:
                    df[f'{cond_col}_{condition}_{sign}_mean'] = -1
        return df
    
    # ì¡°ê±´ê°’ ë§¤í•‘
    condition_map = {1: 'SLOW', 2: 'NORMAL', 3: 'FAST'}
    
    def calculate_condition_reaction_stats(row):
        """ê° í–‰ì— ëŒ€í•´ ì¡°ê±´ë³„, ë¶€í˜¸ë³„ ë°˜ì‘ì†ë„ í‰ê·  ê³„ì‚°"""
        result = {}
        
        # ì´ˆê¸°ê°’ ì„¤ì • (ë°ì´í„° ì—†ì„ ë•Œ -1)
        for cond_col in ['A2-1', 'A2-2']:
            for condition in ['SLOW', 'NORMAL', 'FAST']:
                for sign in ['pos', 'neg']:
                    result[f'{cond_col}_{condition}_{sign}_mean'] = -1
        
        try:
            # ê° ì»¬ëŸ¼ íŒŒì‹±
            a2_1_vals = parse_seq_cached(str(row.get('A2-1', '')))
            a2_2_vals = parse_seq_cached(str(row.get('A2-2', '')))
            a2_3_vals = parse_seq_cached(str(row.get('A2-3', '')))
            a2_4_vals = parse_seq_cached(str(row.get('A2-4', '')))
            
            # ê¸¸ì´ ì²´í¬
            if not a2_1_vals or not a2_2_vals or not a2_3_vals or not a2_4_vals:
                return result
            
            min_len = min(len(a2_1_vals), len(a2_2_vals), len(a2_3_vals), len(a2_4_vals))
            
            # A2-3 == 1ì¸ trialë§Œ ì„ íƒ
            selected_indices = [i for i in range(min_len) if a2_3_vals[i] == 1]
            
            if not selected_indices:
                return result
            
            # A2-1, A2-2 ê°ê°ì— ëŒ€í•´ ì²˜ë¦¬
            for cond_col_name, cond_vals in [('A2-1', a2_1_vals), ('A2-2', a2_2_vals)]:
                # ì¡°ê±´ë³„, ë¶€í˜¸ë³„ ê·¸ë£¹í™”
                groups = {
                    'SLOW': {'pos': [], 'neg': []},
                    'NORMAL': {'pos': [], 'neg': []},
                    'FAST': {'pos': [], 'neg': []}
                }
                
                for idx in selected_indices:
                    # ì¡°ê±´ê°’ ê°€ì ¸ì˜¤ê¸°
                    cond_val = int(cond_vals[idx])
                    reaction_time = a2_4_vals[idx]
                    
                    # ì¡°ê±´ ë§¤í•‘
                    condition_name = condition_map.get(cond_val)
                    if condition_name is None:
                        continue
                    
                    # ë¶€í˜¸ë³„ ë¶„ë¥˜
                    if reaction_time > 0:
                        groups[condition_name]['pos'].append(abs(reaction_time))
                    elif reaction_time < 0:
                        groups[condition_name]['neg'].append(abs(reaction_time))
                
                # í‰ê·  ê³„ì‚°
                for condition in ['SLOW', 'NORMAL', 'FAST']:
                    for sign in ['pos', 'neg']:
                        values = groups[condition][sign]
                        if values:
                            result[f'{cond_col_name}_{condition}_{sign}_mean'] = np.mean(values)
                        # else: ì´ë¯¸ -1ë¡œ ì´ˆê¸°í™”ë¨
            
        except Exception:
            pass  # ì—ëŸ¬ ì‹œ -1 ìœ ì§€
        
        return result
    
    # ê° í–‰ì— ëŒ€í•´ ê³„ì‚°
    stats_df = df.apply(calculate_condition_reaction_stats, axis=1, result_type='expand')
    
    # ê²°ê³¼ ë³‘í•©
    for col in stats_df.columns:
        df[col] = stats_df[col].fillna(-1)
    
    return df


def add_a1_condition_reaction_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    A1 ì»¬ëŸ¼ë“¤ì˜ ì¡°ê±´ë³„, ë¶€í˜¸ë³„ ë°˜ì‘ì†ë„ í‰ê·  ê³„ì‚°
    
    A1-1: condition 1 (1=LEFT, 2=RIGHT)
    A1-2: condition 2 (1=SLOW, 2=NORMAL, 3=FAST)
    A1-3: response (0=No, 1=Yes)
    A1-4: response time (+ / -)
    
    A1-3 == 1ì¸ trialë§Œ ì„ íƒí•˜ì—¬:
    - A1-1 ì¡°ê±´ë³„ (LEFT/RIGHT)
    - A1-2 ì¡°ê±´ë³„ (SLOW/NORMAL/FAST)
    - A1-4ì˜ ë¶€í˜¸ë³„ (ì–‘ìˆ˜/ìŒìˆ˜)
    - ë°˜ì‘ì†ë„ í‰ê·  ê³„ì‚°
    
    ìƒì„±ë˜ëŠ” ë³€ìˆ˜:
    - A1-1_LEFT_pos_mean, A1-1_LEFT_neg_mean
    - A1-1_RIGHT_pos_mean, A1-1_RIGHT_neg_mean
    - A1-2_SLOW_pos_mean, A1-2_SLOW_neg_mean
    - A1-2_NORMAL_pos_mean, A1-2_NORMAL_neg_mean
    - A1-2_FAST_pos_mean, A1-2_FAST_neg_mean
    
    Parameters:
    -----------
    df : pd.DataFrame
        A1-1, A1-2, A1-3, A1-4 ì»¬ëŸ¼ì„ í¬í•¨í•œ ë°ì´í„°í”„ë ˆì„
    
    Returns:
    --------
    pd.DataFrame
        10ê°œì˜ íŒŒìƒë³€ìˆ˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    # í•„ìš”í•œ ì»¬ëŸ¼ ì²´í¬
    required_cols = ['A1-1', 'A1-2', 'A1-3', 'A1-4']
    if not all(col in df.columns for col in required_cols):
        # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ëª¨ë“  íŒŒìƒë³€ìˆ˜ë¥¼ -1ë¡œ ì„¤ì •
        for condition in ['LEFT', 'RIGHT']:
            for sign in ['pos', 'neg']:
                df[f'A1-1_{condition}_{sign}_mean'] = -1
        for condition in ['SLOW', 'NORMAL', 'FAST']:
            for sign in ['pos', 'neg']:
                df[f'A1-2_{condition}_{sign}_mean'] = -1
        return df
    
    # ì¡°ê±´ê°’ ë§¤í•‘
    a1_1_map = {1: 'LEFT', 2: 'RIGHT'}
    a1_2_map = {1: 'SLOW', 2: 'NORMAL', 3: 'FAST'}
    
    def calculate_a1_condition_reaction_stats(row):
        """ê° í–‰ì— ëŒ€í•´ A1 ì¡°ê±´ë³„, ë¶€í˜¸ë³„ ë°˜ì‘ì†ë„ í‰ê·  ê³„ì‚°"""
        result = {}
        
        # ì´ˆê¸°ê°’ ì„¤ì • (ë°ì´í„° ì—†ì„ ë•Œ -1)
        for condition in ['LEFT', 'RIGHT']:
            for sign in ['pos', 'neg']:
                result[f'A1-1_{condition}_{sign}_mean'] = -1
        for condition in ['SLOW', 'NORMAL', 'FAST']:
            for sign in ['pos', 'neg']:
                result[f'A1-2_{condition}_{sign}_mean'] = -1
        
        try:
            # ê° ì»¬ëŸ¼ íŒŒì‹±
            a1_1_vals = parse_seq_cached(str(row.get('A1-1', '')))
            a1_2_vals = parse_seq_cached(str(row.get('A1-2', '')))
            a1_3_vals = parse_seq_cached(str(row.get('A1-3', '')))
            a1_4_vals = parse_seq_cached(str(row.get('A1-4', '')))
            
            # ê¸¸ì´ ì²´í¬
            if not a1_1_vals or not a1_2_vals or not a1_3_vals or not a1_4_vals:
                return result
            
            min_len = min(len(a1_1_vals), len(a1_2_vals), len(a1_3_vals), len(a1_4_vals))
            
            # A1-3 == 1ì¸ trialë§Œ ì„ íƒ
            selected_indices = [i for i in range(min_len) if a1_3_vals[i] == 1]
            
            if not selected_indices:
                return result
            
            # A1-1 ì²˜ë¦¬ (LEFT/RIGHT)
            groups_a1_1 = {
                'LEFT': {'pos': [], 'neg': []},
                'RIGHT': {'pos': [], 'neg': []}
            }
            
            for idx in selected_indices:
                cond_val = int(a1_1_vals[idx])
                reaction_time = a1_4_vals[idx]
                
                condition_name = a1_1_map.get(cond_val)
                if condition_name is None:
                    continue
                
                # ë¶€í˜¸ë³„ ë¶„ë¥˜ (0 ì œì™¸)
                if reaction_time > 0:
                    groups_a1_1[condition_name]['pos'].append(abs(reaction_time))
                elif reaction_time < 0:
                    groups_a1_1[condition_name]['neg'].append(abs(reaction_time))
            
            # A1-1 í‰ê·  ê³„ì‚°
            for condition in ['LEFT', 'RIGHT']:
                for sign in ['pos', 'neg']:
                    values = groups_a1_1[condition][sign]
                    if values:
                        result[f'A1-1_{condition}_{sign}_mean'] = np.mean(values)
            
            # A1-2 ì²˜ë¦¬ (SLOW/NORMAL/FAST)
            groups_a1_2 = {
                'SLOW': {'pos': [], 'neg': []},
                'NORMAL': {'pos': [], 'neg': []},
                'FAST': {'pos': [], 'neg': []}
            }
            
            for idx in selected_indices:
                cond_val = int(a1_2_vals[idx])
                reaction_time = a1_4_vals[idx]
                
                condition_name = a1_2_map.get(cond_val)
                if condition_name is None:
                    continue
                
                # ë¶€í˜¸ë³„ ë¶„ë¥˜ (0 ì œì™¸)
                if reaction_time > 0:
                    groups_a1_2[condition_name]['pos'].append(abs(reaction_time))
                elif reaction_time < 0:
                    groups_a1_2[condition_name]['neg'].append(abs(reaction_time))
            
            # A1-2 í‰ê·  ê³„ì‚°
            for condition in ['SLOW', 'NORMAL', 'FAST']:
                for sign in ['pos', 'neg']:
                    values = groups_a1_2[condition][sign]
                    if values:
                        result[f'A1-2_{condition}_{sign}_mean'] = np.mean(values)
            
        except Exception:
            pass  # ì—ëŸ¬ ì‹œ -1 ìœ ì§€
        
        return result
    
    # ê° í–‰ì— ëŒ€í•´ ê³„ì‚°
    stats_df = df.apply(calculate_a1_condition_reaction_stats, axis=1, result_type='expand')
    
    # ê²°ê³¼ ë³‘í•©
    for col in stats_df.columns:
        df[col] = stats_df[col].fillna(-1)
    
    return df


def add_a3_condition_reaction_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    A3 ì»¬ëŸ¼ë“¤ì˜ ì¡°ê±´ë³„, ë°©í–¥ë³„, ìœ„ì¹˜ë³„ ë°˜ì‘ì†ë„ íŒŒìƒë³€ìˆ˜ ê³„ì‚°
    
    A3-1: Condition1 (1=small, 2=big)
    A3-2: Condition2 (1~8, ì‹œê³„ë°©í–¥ ìœ„ì¹˜)
    A3-3: Condition3 (1=left, 2=right)
    A3-4: Condition4 (1~8, ë³´ì¡° ìœ„ì¹˜)
    A3-5: Response1 (1=valid correct, 2=valid incorrect, 3=invalid correct, 4=invalid incorrect)
    A3-6: Response2 (0=No, 1=Yes)
    A3-7: ResponseTime
    
    A3-6 == 1ì¸ trialë§Œ ì„ íƒí•˜ì—¬:
    
    2ë‹¨ê³„ - Condition1 Ã— Response1 (16ê°œ):
    - A3_small_valid_correct_mean, A3_small_valid_correct_count
    - A3_small_valid_incorrect_mean, A3_small_valid_incorrect_count
    - A3_small_invalid_correct_mean, A3_small_invalid_correct_count
    - A3_small_invalid_incorrect_mean, A3_small_invalid_incorrect_count
    - A3_big_valid_correct_mean, A3_big_valid_correct_count
    - A3_big_valid_incorrect_mean, A3_big_valid_incorrect_count
    - A3_big_invalid_correct_mean, A3_big_invalid_correct_count
    - A3_big_invalid_incorrect_mean, A3_big_invalid_incorrect_count
    
    3ë‹¨ê³„ - ë°©í–¥Â·ìœ„ì¹˜ ê¸°ë°˜ (24ê°œ):
    ì¢Œ/ìš°:
    - A3_left_rt_mean, A3_left_rt_count
    - A3_right_rt_mean, A3_right_rt_count
    - A3_left_right_rt_diff
    
    ìœ„ì¹˜ë³„:
    - A3_pos1_rt_mean ~ A3_pos8_rt_mean
    - A3_pos1_rt_count ~ A3_pos8_rt_count
    
    ìš”ì•½:
    - A3_pos_mean_std
    - A3_pos_with_max_mean
    - A3_pos_with_min_mean
    
    Returns:
    --------
    pd.DataFrame
        40ê°œì˜ íŒŒìƒë³€ìˆ˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    # í•„ìš”í•œ ì»¬ëŸ¼ ì²´í¬
    required_cols = ['A3-1', 'A3-2', 'A3-3', 'A3-5', 'A3-6', 'A3-7']
    if not all(col in df.columns for col in required_cols):
        # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ëª¨ë“  íŒŒìƒë³€ìˆ˜ë¥¼ -1ë¡œ ì„¤ì •
        # 2ë‹¨ê³„ ë³€ìˆ˜ ì´ˆê¸°í™”
        for size in ['small', 'big']:
            for resp in ['valid_correct', 'valid_incorrect', 'invalid_correct', 'invalid_incorrect']:
                df[f'A3_{size}_{resp}_mean'] = -1
                df[f'A3_{size}_{resp}_count'] = 0
        
        # 3ë‹¨ê³„ ë³€ìˆ˜ ì´ˆê¸°í™”
        df['A3_left_rt_mean'] = -1
        df['A3_left_rt_count'] = 0
        df['A3_right_rt_mean'] = -1
        df['A3_right_rt_count'] = 0
        df['A3_left_right_rt_diff'] = -1
        
        for pos in range(1, 9):
            df[f'A3_pos{pos}_rt_mean'] = -1
            df[f'A3_pos{pos}_rt_count'] = 0
        
        df['A3_pos_mean_std'] = -1
        df['A3_pos_with_max_mean'] = -1
        df['A3_pos_with_min_mean'] = -1
        
        return df
    
    # ì¡°ê±´ê°’ ë§¤í•‘
    condition1_map = {1: 'small', 2: 'big'}
    response1_map = {1: 'valid_correct', 2: 'valid_incorrect', 3: 'invalid_correct', 4: 'invalid_incorrect'}
    
    def calculate_a3_stats(row):
        """ê° í–‰ì— ëŒ€í•´ A3 ê´€ë ¨ ëª¨ë“  í†µê³„ ê³„ì‚°"""
        result = {}
        
        # ì´ˆê¸°ê°’ ì„¤ì •
        # 2ë‹¨ê³„ ì´ˆê¸°í™”
        for size in ['small', 'big']:
            for resp in ['valid_correct', 'valid_incorrect', 'invalid_correct', 'invalid_incorrect']:
                result[f'A3_{size}_{resp}_mean'] = -1
                result[f'A3_{size}_{resp}_count'] = 0
        
        # 3ë‹¨ê³„ ì´ˆê¸°í™”
        result['A3_left_rt_mean'] = -1
        result['A3_left_rt_count'] = 0
        result['A3_right_rt_mean'] = -1
        result['A3_right_rt_count'] = 0
        result['A3_left_right_rt_diff'] = -1
        
        for pos in range(1, 9):
            result[f'A3_pos{pos}_rt_mean'] = -1
            result[f'A3_pos{pos}_rt_count'] = 0
        
        result['A3_pos_mean_std'] = -1
        result['A3_pos_with_max_mean'] = -1
        result['A3_pos_with_min_mean'] = -1
        
        try:
            # ê° ì»¬ëŸ¼ íŒŒì‹±
            a3_1_vals = parse_seq_cached(str(row.get('A3-1', '')))
            a3_2_vals = parse_seq_cached(str(row.get('A3-2', '')))
            a3_3_vals = parse_seq_cached(str(row.get('A3-3', '')))
            a3_5_vals = parse_seq_cached(str(row.get('A3-5', '')))
            a3_6_vals = parse_seq_cached(str(row.get('A3-6', '')))
            a3_7_vals = parse_seq_cached(str(row.get('A3-7', '')))
            
            # ê¸¸ì´ ì²´í¬ (ì‹œí€€ìŠ¤ ë¶ˆì¼ì¹˜ ëŒ€ë¹„)
            if not all([a3_1_vals, a3_2_vals, a3_3_vals, a3_5_vals, a3_6_vals, a3_7_vals]):
                return result
            
            min_len = min(len(a3_1_vals), len(a3_2_vals), len(a3_3_vals), 
                         len(a3_5_vals), len(a3_6_vals), len(a3_7_vals))
            
            if min_len == 0:
                return result
            
            # A3-6 == 1ì¸ trialë§Œ ì„ íƒ
            selected_indices = [i for i in range(min_len) if i < len(a3_6_vals) and a3_6_vals[i] == 1]
            
            if not selected_indices:
                return result
            
            # ==============================================
            # 2ë‹¨ê³„: Condition1 Ã— Response1
            # ==============================================
            cond1_resp1_groups = {}
            for size in ['small', 'big']:
                for resp in ['valid_correct', 'valid_incorrect', 'invalid_correct', 'invalid_incorrect']:
                    cond1_resp1_groups[f'{size}_{resp}'] = []
            
            for idx in selected_indices:
                try:
                    cond1_val = int(a3_1_vals[idx])
                    resp1_val = int(a3_5_vals[idx])
                    rt_val = a3_7_vals[idx]
                    
                    size_name = condition1_map.get(cond1_val)
                    resp_name = response1_map.get(resp1_val)
                    
                    if size_name and resp_name:
                        key = f'{size_name}_{resp_name}'
                        cond1_resp1_groups[key].append(rt_val)
                except (IndexError, ValueError):
                    continue
            
            # 2ë‹¨ê³„ í†µê³„ ê³„ì‚°
            for key, values in cond1_resp1_groups.items():
                result[f'A3_{key}_count'] = len(values)
                if values:
                    result[f'A3_{key}_mean'] = np.mean(values)
            
            # ==============================================
            # 3ë‹¨ê³„: ë°©í–¥Â·ìœ„ì¹˜ ê¸°ë°˜
            # ==============================================
            
            # ì¢Œ/ìš° ê·¸ë£¹
            left_rts = []
            right_rts = []
            
            for idx in selected_indices:
                try:
                    direction = int(a3_3_vals[idx])
                    rt_val = a3_7_vals[idx]
                    
                    if direction == 1:  # left
                        left_rts.append(rt_val)
                    elif direction == 2:  # right
                        right_rts.append(rt_val)
                except (IndexError, ValueError):
                    continue
            
            # ì¢Œ/ìš° í†µê³„
            if left_rts:
                result['A3_left_rt_mean'] = np.mean(left_rts)
                result['A3_left_rt_count'] = len(left_rts)
            
            if right_rts:
                result['A3_right_rt_mean'] = np.mean(right_rts)
                result['A3_right_rt_count'] = len(right_rts)
            
            # ì¢Œìš° ì°¨ì´
            if left_rts and right_rts:
                result['A3_left_right_rt_diff'] = result['A3_left_rt_mean'] - result['A3_right_rt_mean']
            
            # ìœ„ì¹˜ë³„ ê·¸ë£¹
            position_groups = {pos: [] for pos in range(1, 9)}
            
            for idx in selected_indices:
                try:
                    position = int(a3_2_vals[idx])
                    rt_val = a3_7_vals[idx]
                    
                    if 1 <= position <= 8:
                        position_groups[position].append(rt_val)
                except (IndexError, ValueError):
                    continue
            
            # ìœ„ì¹˜ë³„ í†µê³„
            position_means = []
            for pos in range(1, 9):
                values = position_groups[pos]
                result[f'A3_pos{pos}_rt_count'] = len(values)
                if values:
                    mean_val = np.mean(values)
                    result[f'A3_pos{pos}_rt_mean'] = mean_val
                    position_means.append(mean_val)
            
            # ìœ„ì¹˜ ê¸°ë°˜ ìš”ì•½ ì§€í‘œ
            if position_means and len(position_means) >= 2:
                result['A3_pos_mean_std'] = np.std(position_means)
                
                # ìµœëŒ€/ìµœì†Œ í‰ê· ì„ ê°€ì§„ ìœ„ì¹˜ ì°¾ê¸°
                valid_positions = [(pos, result[f'A3_pos{pos}_rt_mean']) 
                                  for pos in range(1, 9) 
                                  if result[f'A3_pos{pos}_rt_mean'] != -1]
                
                if valid_positions:
                    max_pos = min([pos for pos, val in valid_positions 
                                  if val == max(v for _, v in valid_positions)])
                    min_pos = min([pos for pos, val in valid_positions 
                                  if val == min(v for _, v in valid_positions)])
                    
                    result['A3_pos_with_max_mean'] = max_pos
                    result['A3_pos_with_min_mean'] = min_pos
            
        except Exception:
            pass  # ì—ëŸ¬ ì‹œ ì´ˆê¸°ê°’ ìœ ì§€
        
        return result
    
    # ê° í–‰ì— ëŒ€í•´ ê³„ì‚°
    stats_df = df.apply(calculate_a3_stats, axis=1, result_type='expand')
    
    # ê²°ê³¼ ë³‘í•©
    for col in stats_df.columns:
        if col not in df.columns:
            df[col] = stats_df[col].fillna(-1 if 'mean' in col or 'diff' in col or 'std' in col or 'with' in col else 0)
    
    return df


def add_a4_condition_reaction_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    A4 ì»¬ëŸ¼ë“¤ì˜ ì¡°ê±´ë³„ ë°˜ì‘ì†ë„ í‰ê·  ê³„ì‚°
    
    A4-1: Condition1 (1=con, 2=incon)
    A4-2: Condition2 (1=red, 2=green)
    A4-3: Response (0=ì˜¤ë‹µ, 1=ì •ë‹µ)
    A4-4: (ì‚¬ìš© ì•ˆ í•¨)
    A4-5: ResponseTime
    
    A4-3 == 1ì¸ trial(ì •ë‹µ trial)ë§Œ ì„ íƒí•˜ì—¬:
    - A4-1 Ã— A4-2 ì¡°í•©ë³„ A4-5 í‰ê·  ê³„ì‚°
    
    ìƒì„±ë˜ëŠ” ë³€ìˆ˜:
    - A4_con_red_rt_mean        (A4-1=1, A4-2=1)
    - A4_con_green_rt_mean      (A4-1=1, A4-2=2)
    - A4_incon_red_rt_mean      (A4-1=2, A4-2=1)
    - A4_incon_green_rt_mean    (A4-1=2, A4-2=2)
    
    Parameters:
    -----------
    df : pd.DataFrame
        A4-1, A4-2, A4-3, A4-5 ì»¬ëŸ¼ì„ í¬í•¨í•œ ë°ì´í„°í”„ë ˆì„
    
    Returns:
    --------
    pd.DataFrame
        4ê°œì˜ íŒŒìƒë³€ìˆ˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    # í•„ìš”í•œ ì»¬ëŸ¼ ì²´í¬
    required_cols = ['A4-1', 'A4-2', 'A4-3', 'A4-5']
    if not all(col in df.columns for col in required_cols):
        # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ëª¨ë“  íŒŒìƒë³€ìˆ˜ë¥¼ -1ë¡œ ì„¤ì •
        df['A4_con_red_rt_mean'] = -1
        df['A4_con_green_rt_mean'] = -1
        df['A4_incon_red_rt_mean'] = -1
        df['A4_incon_green_rt_mean'] = -1
        return df
    
    # ì¡°ê±´ê°’ ë§¤í•‘
    a4_1_map = {1: 'con', 2: 'incon'}
    a4_2_map = {1: 'red', 2: 'green'}
    
    def calculate_a4_stats(row):
        """ê° í–‰ì— ëŒ€í•´ A4 ì¡°í•©ë³„ í‰ê·  ê³„ì‚°"""
        result = {
            'A4_con_red_rt_mean': -1,
            'A4_con_green_rt_mean': -1,
            'A4_incon_red_rt_mean': -1,
            'A4_incon_green_rt_mean': -1,
        }
        
        try:
            # ê° ì»¬ëŸ¼ íŒŒì‹±
            a4_1_vals = parse_seq_cached(str(row.get('A4-1', '')))
            a4_2_vals = parse_seq_cached(str(row.get('A4-2', '')))
            a4_3_vals = parse_seq_cached(str(row.get('A4-3', '')))
            a4_5_vals = parse_seq_cached(str(row.get('A4-5', '')))
            
            # ê¸¸ì´ ì²´í¬ (ì‹œí€€ìŠ¤ ë¶ˆì¼ì¹˜ ëŒ€ë¹„)
            if not all([a4_1_vals, a4_2_vals, a4_3_vals, a4_5_vals]):
                return result
            
            min_len = min(len(a4_1_vals), len(a4_2_vals), len(a4_3_vals), len(a4_5_vals))
            
            if min_len == 0:
                return result
            
            # A4-3 == 1ì¸ trialë§Œ ì„ íƒ (ì •ë‹µë§Œ)
            selected_indices = [i for i in range(min_len) if i < len(a4_3_vals) and a4_3_vals[i] == 1]
            
            if not selected_indices:
                return result
            
            # ì¡°í•©ë³„ ê·¸ë£¹í™”
            groups = {
                'con_red': [],
                'con_green': [],
                'incon_red': [],
                'incon_green': [],
            }
            
            for idx in selected_indices:
                try:
                    cond1_val = int(a4_1_vals[idx])
                    cond2_val = int(a4_2_vals[idx])
                    rt_val = a4_5_vals[idx]
                    
                    cond1_name = a4_1_map.get(cond1_val)
                    cond2_name = a4_2_map.get(cond2_val)
                    
                    if cond1_name and cond2_name:
                        key = f'{cond1_name}_{cond2_name}'
                        groups[key].append(rt_val)
                except (IndexError, ValueError):
                    continue
            
            # í‰ê·  ê³„ì‚°
            for key, values in groups.items():
                if values:
                    result[f'A4_{key}_rt_mean'] = np.mean(values)
            
        except Exception:
            pass  # ì—ëŸ¬ ì‹œ -1 ìœ ì§€
        
        return result
    
    # ê° í–‰ì— ëŒ€í•´ ê³„ì‚°
    stats_df = df.apply(calculate_a4_stats, axis=1, result_type='expand')
    
    # ê²°ê³¼ ë³‘í•©
    for col in stats_df.columns:
        df[col] = stats_df[col].fillna(-1)
    
    return df



